{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12337654,
          "sourceType": "datasetVersion",
          "datasetId": 7777606
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook90dc24bd09",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/dacon_new_drug/blob/main/20250703\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "rSjoRb2M4RQl"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "biniroun_drug_data_path = kagglehub.dataset_download('biniroun/drug-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "SqyPks8F4RQo"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle 노트북 상단에 RDKit 설치 명령어 추가\n",
        "!pip install -q rdkit-pypi"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T00:22:52.48252Z",
          "iopub.execute_input": "2025-07-03T00:22:52.4828Z",
          "iopub.status.idle": "2025-07-03T00:22:56.302568Z",
          "shell.execute_reply.started": "2025-07-03T00:22:52.482763Z",
          "shell.execute_reply": "2025-07-03T00:22:56.300962Z"
        },
        "id": "zrj2tmT-4RQo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 경우 다른 라이브러리도 함께 업그레이드/설치\n",
        "!pip install --upgrade scikit-learn pandas numpy xgboost lightgbm catboost"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T00:23:00.945041Z",
          "iopub.execute_input": "2025-07-03T00:23:00.945359Z",
          "iopub.status.idle": "2025-07-03T00:23:06.54787Z",
          "shell.execute_reply.started": "2025-07-03T00:23:00.945324Z",
          "shell.execute_reply": "2025-07-03T00:23:06.547014Z"
        },
        "id": "ComQI34F4RQp",
        "outputId": "db202f1a-8951-4687-c67e-8c9e439041e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.3.1)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.2)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\nRequirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.7.2)\nRequirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.0.9)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Draw\n",
        "# from rdkit.Chem import Descriptors\n",
        "# from collections import Counter\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from scipy.stats import pearsonr"
      ],
      "metadata": {
        "trusted": true,
        "id": "mjGNAMIp4RQq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 학습 데이터 불러오기\n",
        "# path = '/kaggle/input/drug-data'\n",
        "# df = pd.read_csv(os.path.join(path, 'train.csv'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "c2mexsxD4RQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# smiles = df['Canonical_Smiles'][1] # idx\n",
        "\n",
        "# # SMILES string을 RDKit molecule object 변환\n",
        "# mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "# # 변환이 잘 되었는지 확인\n",
        "# if mol is not None:\n",
        "#     # 분자 구조 이미지 파일로 그리기\n",
        "#     img = Draw.MolToImage(mol)\n",
        "#     # 2D 분자 구조 이미지 저장\n",
        "#     img.save(\"molecule.png\")\n",
        "# else:\n",
        "#     print(\"Invalid SMILES string\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "aVYWruAP4RQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 각 SMILES에서 원자 정보 추출\n",
        "# element_counter = Counter()\n",
        "# atom_counts = []\n",
        "# invalid_smiles = []\n",
        "# mol_weights = []\n",
        "\n",
        "# for idx, smi in enumerate(df['Canonical_Smiles']):\n",
        "#     mol = Chem.MolFromSmiles(smi)\n",
        "#     if mol is None:\n",
        "#         invalid_smiles.append((idx, smi))\n",
        "#         continue\n",
        "#     atoms = [atom.GetSymbol() for atom in mol.GetAtoms()]\n",
        "#     mol_weight = Descriptors.MolWt(mol)\n",
        "#     element_counter.update(atoms)\n",
        "#     atom_counts.append(len(atoms))\n",
        "#     mol_weights.append(mol_weight)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hQ2HSHru4RQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 평균 원자 수 (H 제외(heavy atoms), SMILES에만 포함된 원자)\n",
        "# df['atom_count'] = atom_counts\n",
        "# df['mol_weight'] = mol_weights\n",
        "\n",
        "# mean_atoms = np.mean([c for c in atom_counts if c is not None])"
      ],
      "metadata": {
        "trusted": true,
        "id": "utqx-Rcx4RQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 원소 등장 빈도 (H 제외)\n",
        "# # plt.figure(figsize=(12, 6))\n",
        "# fig, ax = plt.subplots(figsize=(12, 6))\n",
        "# elements, counts = zip(*element_counter.most_common())\n",
        "# bars = ax.bar(elements, counts, color='skyblue')\n",
        "# plt.title('Atom Frequency Distribution')\n",
        "# plt.xlabel('Atom')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# for bar in bars:\n",
        "#     height = bar.get_height()\n",
        "#     plt.text(bar.get_x() + bar.get_width()/2, height,\n",
        "#              f'{height}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "NQ2AfxfY4RQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 화합물당 원자 수 히스토그램\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# plt.hist(atom_counts, bins=20, color='orange', edgecolor='black')\n",
        "# plt.title('Distribution of heavy atoms per compound')\n",
        "# plt.xlabel('Number of heavy atoms')\n",
        "# plt.ylabel('Number of compound')\n",
        "# plt.grid(True, linestyle='--', alpha=0.5)\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "AAlNe0MF4RQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Inhibition 값 히스토그램\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# # 5% 단위로 분리\n",
        "# plt.hist(df['Inhibition'], bins=20, color='green', edgecolor='black')\n",
        "# plt.title('Target Distribution')\n",
        "# plt.xlabel('Inhibition ')\n",
        "# plt.ylabel('Number of compound')\n",
        "# plt.grid(True, linestyle='--', alpha=0.5)\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Kvji5o8D4RQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 분자량 히스토그램\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# plt.hist(df['mol_weight'], bins=20, color='red', edgecolor='black')\n",
        "# plt.title('Mol Weight Distribution')\n",
        "# plt.xlabel('mol_weight')\n",
        "# plt.ylabel('Number of compound')\n",
        "# plt.grid(True, linestyle='--', alpha=0.5)\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "53fQBej04RQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 통계 정보\n",
        "# print(f\"Number of valid SMILES: {len(atom_counts)} / {len(df)}\")\n",
        "# print(f\"Number of Invalid SMILES: {len(invalid_smiles)}\")\n",
        "# print(f\"Average number of heavy atoms: {mean_atoms:.2f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "PU8Igwft4RQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 데이터프레임: df['smiles'], df['target'] 가정\n",
        "# df['smiles_length'] = df['Canonical_Smiles'].apply(len)\n",
        "\n",
        "# # 상관계수 계산\n",
        "# corr, p_value = pearsonr(df['smiles_length'], df['Inhibition'])\n",
        "\n",
        "# print(f\" Pearson 상관계수: {corr:.3f}\")\n",
        "# print(f\" p-value: {p_value:.3e}\")\n",
        "# print(\"=\"*120)\n",
        "\n",
        "# # 산점도 시각화\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.scatter(df['smiles_length'], df['Inhibition'], alpha=0.6, color='teal', edgecolors='k')\n",
        "# plt.title('SMILES Length vs Inhibition')\n",
        "# plt.xlabel('SMILES Length')\n",
        "# plt.ylabel('Inhibition')\n",
        "# plt.grid(True, linestyle='--', alpha=0.5)\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "iZchoW_84RQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 상관계수 계산\n",
        "# corr, p_value = pearsonr(df['mol_weight'], df['Inhibition'])\n",
        "\n",
        "# print(f\" Pearson 상관계수: {corr:.3f}\")\n",
        "# print(f\" p-value: {p_value:.3e}\")\n",
        "# print(\"=\"*120)\n",
        "\n",
        "# # 산점도 시각화\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.scatter(df['mol_weight'], df['Inhibition'], alpha=0.6, color='steelblue', edgecolors='k')\n",
        "# plt.title('Mol Weight vs Inhibition')\n",
        "# plt.xlabel('Mol Weight')\n",
        "# plt.ylabel('Inhibition')\n",
        "# plt.grid(True, linestyle='--', alpha=0.5)\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "e7b5ytrv4RQu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df.columns.tolist())\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "aNXtM2Bd4RQu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from lightgbm import LGBMRegressor\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# path = '/kaggle/input/drug-data'\n",
        "# train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "\n",
        "# # ✅ RDKit 파생변수 생성 함수\n",
        "# def featurize(smiles):\n",
        "#     mol = Chem.MolFromSmiles(smiles)\n",
        "#     if mol is None:\n",
        "#         return np.nan, np.nan\n",
        "#     mol_wt = Descriptors.MolWt(mol)\n",
        "#     tpsa = Descriptors.TPSA(mol)\n",
        "#     return mol_wt, tpsa\n",
        "\n",
        "# train[['MolWt', 'TPSA']] = train['Canonical_Smiles'].apply(\n",
        "#     lambda x: pd.Series(featurize(x))\n",
        "# )\n",
        "\n",
        "# # ✅ 파생 변수 생성\n",
        "# train['smiles_length'] = train['Canonical_Smiles'].apply(len)\n",
        "# train['is_heavy_mol'] = (train['MolWt'] > 500).astype(int)\n",
        "# train['is_long_smiles'] = (train['smiles_length'] > 60).astype(int)\n",
        "# train['is_low_inhibition'] = (train['Inhibition'] < 10).astype(int)\n",
        "# train['log_inhibition'] = np.log1p(train['Inhibition'])\n",
        "\n",
        "# # ✅ Feature / Target 설정\n",
        "# features = ['MolWt', 'TPSA', 'smiles_length', 'is_heavy_mol', 'is_long_smiles', 'is_low_inhibition']\n",
        "# X = train[features]\n",
        "# y = train['log_inhibition']\n",
        "\n",
        "# # ✅ KFold + Quantile Loss\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# oof_preds = np.zeros(len(train))\n",
        "\n",
        "# for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "#     X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "#     X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "#     model = LGBMRegressor(\n",
        "#         objective='quantile',\n",
        "#         alpha=0.5,\n",
        "#         n_estimators=200,\n",
        "#         learning_rate=0.05,\n",
        "#         random_state=42\n",
        "#     )\n",
        "#     model.fit(X_train, y_train)\n",
        "#     oof_preds[val_idx] = model.predict(X_val)\n",
        "\n",
        "# # ✅ 평가 (역변환)\n",
        "# rmse = np.sqrt(mean_squared_error(np.expm1(y), np.expm1(oof_preds)))\n",
        "# print(f\"✅ RMSE (Quantile Loss + log1p 역변환): {rmse:.5f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "THNY2QxH4RQu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from catboost import CatBoostRegressor, Pool\n",
        "\n",
        "# # ✅ 데이터 로드\n",
        "# path = '/kaggle/input/drug-data'  # Colab이면 로컬 경로로 수정\n",
        "# train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "\n",
        "# # ✅ 파생변수 생성\n",
        "# train['smiles_length'] = train['Canonical_Smiles'].apply(len)\n",
        "# train['is_long_smiles'] = (train['smiles_length'] > 60).astype(int)\n",
        "# train['is_low_inhibition'] = (train['Inhibition'] < 10).astype(int)\n",
        "# train['is_high_inhibition'] = (train['Inhibition'] > 90).astype(int)\n",
        "\n",
        "# # ✅ log1p 타깃 변환\n",
        "# train['log_inhibition'] = np.log1p(train['Inhibition'])\n",
        "\n",
        "# # ✅ 입력 특성 선택\n",
        "# features = ['smiles_length', 'is_long_smiles', 'is_low_inhibition', 'is_high_inhibition']\n",
        "# X = train[features]\n",
        "# y = train['log_inhibition']\n",
        "\n",
        "# # ✅ KFold 교차검증\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# oof_preds = np.zeros(len(train))\n",
        "\n",
        "# for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
        "#     X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "#     y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "\n",
        "#     train_pool = Pool(X_tr, y_tr)\n",
        "#     val_pool = Pool(X_val, y_val)\n",
        "\n",
        "#     model = CatBoostRegressor(\n",
        "#         iterations=1000,\n",
        "#         learning_rate=0.05,\n",
        "#         depth=6,\n",
        "#         loss_function='Quantile:alpha=0.5',  # Median\n",
        "#         random_seed=42,\n",
        "#         verbose=0\n",
        "#     )\n",
        "\n",
        "#     model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50)\n",
        "#     oof_preds[val_idx] = model.predict(X_val)\n",
        "\n",
        "# # ✅ 평가 (log1p 역변환 후 RMSE)\n",
        "# rmse = np.sqrt(mean_squared_error(np.expm1(y), np.expm1(oof_preds)))\n",
        "# print(f\"✅ CatBoost RMSE (exp scale): {rmse:.5f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "8ezR6cNz4RQu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # test.csv 로드 및 동일한 파생변수 생성\n",
        "# test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
        "# test['smiles_length'] = test['Canonical_Smiles'].apply(len)\n",
        "# test['is_long_smiles'] = (test['smiles_length'] > 60).astype(int)\n",
        "# test['is_low_inhibition'] = 0  # 예측 대상이므로 실제 값 없음\n",
        "# test['is_high_inhibition'] = 0\n",
        "\n",
        "# test_X = test[features]\n",
        "\n",
        "# # 5개 모델 평균 앙상블\n",
        "# preds = np.zeros(len(test_X))\n",
        "# for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
        "#     model = CatBoostRegressor(\n",
        "#         iterations=1000,\n",
        "#         learning_rate=0.05,\n",
        "#         depth=6,\n",
        "#         loss_function='Quantile:alpha=0.5',\n",
        "#         random_seed=42,\n",
        "#         verbose=0\n",
        "#     )\n",
        "#     model.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
        "#     preds += model.predict(test_X) / kf.get_n_splits()\n",
        "\n",
        "# # log1p 역변환 후 제출\n",
        "# submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "# submission['Inhibition'] = np.expm1(preds)\n",
        "# submission.to_csv(\"submission_catboost.csv\", index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "GeCXmfrT4RQx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # ✅ 확실한 예측 및 저장 코드\n",
        "# submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "# submission['Inhibition'] = np.expm1(preds)  # 로그 역변환 필수\n",
        "# print(submission['Inhibition'].describe())  # 분포 확인\n",
        "\n",
        "# submission.to_csv(\"submission_catboost_fixed.csv\", index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "isn6OMW-4RQy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(8, 4))\n",
        "# plt.hist(submission['Inhibition'], bins=30, color='skyblue', edgecolor='black')\n",
        "# plt.title(\"Distribution of Predicted Inhibition Values\")\n",
        "# plt.xlabel(\"Inhibition\")\n",
        "# plt.ylabel(\"Frequency\")\n",
        "# plt.grid(True)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "43MFJt554RQy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # ✅ 라이브러리\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from catboost import CatBoostRegressor, Pool\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# path = '/kaggle/input/drug-data'\n",
        "# train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "# test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
        "# submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "\n",
        "\n",
        "# # ✅ SMILES → RDKit mol 객체로 변환\n",
        "# def smiles_to_mol(smiles):\n",
        "#     try:\n",
        "#         return Chem.MolFromSmiles(smiles)\n",
        "#     except:\n",
        "#         return None\n",
        "\n",
        "# train[\"mol\"] = train[\"Canonical_Smiles\"].apply(smiles_to_mol)\n",
        "# test[\"mol\"] = test[\"Canonical_Smiles\"].apply(smiles_to_mol)\n",
        "\n",
        "# # ✅ 파생변수 생성\n",
        "# def make_features(df, is_train=True):\n",
        "#     df[\"mol_wt\"] = df[\"mol\"].apply(lambda m: Descriptors.MolWt(m) if m else 0)\n",
        "#     df[\"smiles_len\"] = df[\"Canonical_Smiles\"].apply(len)\n",
        "#     df[\"is_heavy_mol\"] = (df[\"mol_wt\"] > 500).astype(int)\n",
        "#     df[\"long_smiles\"] = (df[\"smiles_len\"] > 70).astype(int)\n",
        "#     if is_train:\n",
        "#         df[\"low_inhibition\"] = (df[\"Inhibition\"] < 30).astype(int)\n",
        "#     return df\n",
        "\n",
        "# train = make_features(train, is_train=True)\n",
        "# test = make_features(test, is_train=False)\n",
        "\n",
        "# # ✅ Target log1p 변환\n",
        "# train[\"target\"] = np.log1p(train[\"Inhibition\"])\n",
        "\n",
        "# # ✅ 모델 학습\n",
        "# features = [\"mol_wt\", \"smiles_len\", \"is_heavy_mol\", \"long_smiles\"]\n",
        "# X = train[features]\n",
        "# y = train[\"target\"]\n",
        "# X_test = test[features]\n",
        "\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# model = CatBoostRegressor(\n",
        "#     iterations=1000,\n",
        "#     learning_rate=0.03,\n",
        "#     depth=6,\n",
        "#     loss_function=\"Quantile:alpha=0.5\",  # Quantile Regression\n",
        "#     early_stopping_rounds=30,\n",
        "#     random_seed=42,\n",
        "#     verbose=100\n",
        "# )\n",
        "\n",
        "# model.fit(Pool(X_train, y_train), eval_set=Pool(X_valid, y_valid))\n",
        "\n",
        "# # ✅ 예측 및 역변환\n",
        "# preds = model.predict(X_test)\n",
        "# submission[\"Inhibition\"] = np.expm1(preds)  # log1p 역변환\n",
        "\n",
        "# # ✅ 저장\n",
        "# submission.to_csv(\"submission_catboost_v2.csv\", index=False)\n",
        "\n",
        "# # ✅ 예측 분포 시각화\n",
        "# plt.figure(figsize=(8, 4))\n",
        "# plt.hist(submission[\"Inhibition\"], bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
        "# plt.title(\"Distribution of Predicted Inhibition Values\")\n",
        "# plt.xlabel(\"Inhibition\")\n",
        "# plt.ylabel(\"Frequency\")\n",
        "# plt.grid(True)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "O5D8vMMD4RQy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # 라이브러리\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from catboost import CatBoostRegressor, Pool\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# path = '/kaggle/input/drug-data'\n",
        "# train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "# test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
        "# submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "\n",
        "\n",
        "\n",
        "# # 로그 변환\n",
        "# train[\"Inhibition_log\"] = np.log1p(train[\"Inhibition\"])\n",
        "\n",
        "# # 서브구조 파생변수 추가 함수\n",
        "# def add_smiles_features(df):\n",
        "#     features = ['Cl', 'Br', 'F', 'N=', 'C#C', 'c1ccccc1']  # 예시\n",
        "#     for f in features:\n",
        "#         df[f\"has_{f}\"] = df[\"Canonical_Smiles\"].str.contains(f, regex=False).astype(int)\n",
        "#     return df\n",
        "\n",
        "# train = add_smiles_features(train)\n",
        "# test = add_smiles_features(test)\n",
        "\n",
        "# # 피처 및 타겟 분리\n",
        "# X = train.drop(columns=[\"ID\", \"Inhibition\", \"Inhibition_log\", \"Canonical_Smiles\"])\n",
        "# y = train[\"Inhibition_log\"]\n",
        "# X_test = test.drop(columns=[\"ID\", \"Canonical_Smiles\"])\n",
        "\n",
        "# # 이상치 가중치\n",
        "# sample_weight = np.where(train[\"Inhibition\"] > 45, 2.0, 1.0)\n",
        "\n",
        "# # train/valid split\n",
        "# X_train, X_valid, y_train, y_valid, sw_train, sw_valid = train_test_split(\n",
        "#     X, y, sample_weight, test_size=0.2, random_state=42\n",
        "# )\n",
        "\n",
        "# # 모델 학습 (alpha=0.9)\n",
        "# model_q90 = CatBoostRegressor(\n",
        "#     loss_function='Quantile:alpha=0.9',\n",
        "#     iterations=500,\n",
        "#     learning_rate=0.05,\n",
        "#     depth=6,\n",
        "#     random_state=42,\n",
        "#     verbose=100\n",
        "# )\n",
        "\n",
        "# model_q90.fit(Pool(X_train, y_train, weight=sw_train),\n",
        "#               eval_set=Pool(X_valid, y_valid, weight=sw_valid))\n",
        "\n",
        "# # 예측 및 복원\n",
        "# preds = model_q90.predict(X_test)\n",
        "# submission = pd.DataFrame({\n",
        "#     \"ID\": test[\"ID\"],\n",
        "#     \"Inhibition\": np.expm1(preds)  # 로그 복원\n",
        "# })\n",
        "\n",
        "# # 저장\n",
        "# submission.to_csv(\"submission_catboost_quantile090.csv\", index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "3UKO3KuL4RQz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # ✅ 라이브러리\n",
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.linear_model import Ridge\n",
        "# from sklearn.metrics import mean_absolute_error\n",
        "# from catboost import CatBoostRegressor\n",
        "# from lightgbm import LGBMRegressor\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# path = '/kaggle/input/drug-data'\n",
        "# train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "# test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
        "# submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "\n",
        "# # ✅ 파생변수 생성 함수\n",
        "# def smiles_to_descriptors(smiles):\n",
        "#     mol = Chem.MolFromSmiles(smiles)\n",
        "#     if mol:\n",
        "#         return {\n",
        "#             'MolWt': Descriptors.MolWt(mol),\n",
        "#             'NumHDonors': Descriptors.NumHDonors(mol),\n",
        "#             'NumHAcceptors': Descriptors.NumHAcceptors(mol),\n",
        "#             'TPSA': Descriptors.TPSA(mol),\n",
        "#             'LogP': Descriptors.MolLogP(mol)\n",
        "#         }\n",
        "#     else:\n",
        "#         return {'MolWt': 0, 'NumHDonors': 0, 'NumHAcceptors': 0, 'TPSA': 0, 'LogP': 0}\n",
        "\n",
        "# # ✅ 파생변수 적용\n",
        "# train_desc = train['Canonical_Smiles'].apply(smiles_to_descriptors).apply(pd.Series)\n",
        "# test_desc = test['Canonical_Smiles'].apply(smiles_to_descriptors).apply(pd.Series)\n",
        "\n",
        "# train = pd.concat([train, train_desc], axis=1)\n",
        "# test = pd.concat([test, test_desc], axis=1)\n",
        "\n",
        "# # ✅ 모델 입력 설정\n",
        "# features = ['MolWt', 'NumHDonors', 'NumHAcceptors', 'TPSA', 'LogP']\n",
        "# X = train[features].values\n",
        "# X_test = test[features].values\n",
        "# y = train['Inhibition'].values\n",
        "\n",
        "# # ✅ 극단값 가중치 부여 (예: 40 이상인 경우 가중치 ↑)\n",
        "# sample_weight = np.where(y >= 40, 2.0, 1.0)\n",
        "\n",
        "# # ✅ OOF 및 테스트 예측 저장용\n",
        "# oof_cat = np.zeros(len(train))\n",
        "# oof_lgb = np.zeros(len(train))\n",
        "# preds_cat = np.zeros(len(test))\n",
        "# preds_lgb = np.zeros(len(test))\n",
        "\n",
        "# # ✅ KFold 설정\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# # ✅ 개별 모델 학습 및 예측\n",
        "# for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "#     X_tr, X_val = X[train_idx], X[val_idx]\n",
        "#     y_tr, y_val = y[train_idx], y[val_idx]\n",
        "#     w_tr = sample_weight[train_idx]\n",
        "\n",
        "#     # ✅ CatBoost\n",
        "#     cat = CatBoostRegressor(verbose=0, iterations=500, learning_rate=0.05)\n",
        "#     cat.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "#     oof_cat[val_idx] = cat.predict(X_val)\n",
        "#     preds_cat += cat.predict(X_test) / kf.n_splits\n",
        "\n",
        "#     # ✅ LightGBM\n",
        "#     lgb = LGBMRegressor(n_estimators=500, learning_rate=0.05)\n",
        "#     lgb.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "#     oof_lgb[val_idx] = lgb.predict(X_val)\n",
        "#     preds_lgb += lgb.predict(X_test) / kf.n_splits\n",
        "\n",
        "# # ✅ 메타모델 입력 구성\n",
        "# X_meta = np.vstack([oof_cat, oof_lgb]).T\n",
        "# X_test_meta = np.vstack([preds_cat, preds_lgb]).T\n",
        "\n",
        "# # ✅ 메타모델 (Ridge)\n",
        "# meta_model = Ridge()\n",
        "# meta_model.fit(X_meta, y, sample_weight=sample_weight)\n",
        "# final_preds = meta_model.predict(X_test_meta)\n",
        "\n",
        "# # ✅ 제출\n",
        "# submission['Inhibition'] = final_preds\n",
        "# submission.to_csv('submission_stacking.csv', index=False)\n",
        "# print(\"✅ 최종 제출 파일 저장 완료.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "sVvnr2KO4RQz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "print(\"StandardScaler 로딩 성공\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lnb9tG3q4RQz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.linear_model import QuantileRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "import optuna\n",
        "\n",
        "# ✅ 데이터 로딩\n",
        "path = '/kaggle/input/drug-data'\n",
        "train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
        "submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "\n",
        "# ✅ 전처리 완료된 특징 불러오기 (RDKit 기반)\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Crippen import MolLogP\n",
        "from rdkit.Chem.Descriptors import MolWt, NumRotatableBonds\n",
        "from rdkit.Chem.Lipinski import NumHDonors, NumHAcceptors\n",
        "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def extract_features(df):\n",
        "    mols = [Chem.MolFromSmiles(smi) for smi in df['Canonical_Smiles']]\n",
        "    features = {\n",
        "        'MolWt': [MolWt(mol) if mol else np.nan for mol in mols],\n",
        "        'LogP': [MolLogP(mol) if mol else np.nan for mol in mols],\n",
        "        'NumHDonors': [NumHDonors(mol) if mol else np.nan for mol in mols],\n",
        "        'NumHAcceptors': [NumHAcceptors(mol) if mol else np.nan for mol in mols],\n",
        "        'TPSA': [CalcTPSA(mol) if mol else np.nan for mol in mols],\n",
        "        'NumRotatableBonds': [NumRotatableBonds(mol) if mol else np.nan for mol in mols],\n",
        "        'RingCount': [mol.GetRingInfo().NumRings() if mol else np.nan for mol in mols]\n",
        "    }\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "X_train = extract_features(train)\n",
        "X_test = extract_features(test)\n",
        "y_train = train[\"Inhibition\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Optuna Objective 정의\n",
        "def objective(trial):\n",
        "    alpha = trial.suggest_float(\"alpha\", 0.7, 0.95)\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    maes = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X_train_scaled):\n",
        "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        model = QuantileRegressor(quantile=alpha, alpha=0, solver='highs')\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_val)\n",
        "        maes.append(mean_absolute_error(y_val, y_pred))\n",
        "\n",
        "    return np.mean(maes)\n",
        "\n",
        "# ✅ Optuna 실행\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "best_alpha = study.best_params['alpha']\n",
        "\n",
        "# ✅ 최종 모델 학습\n",
        "final_model = QuantileRegressor(quantile=best_alpha, alpha=0, solver='highs')\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "preds = final_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ 제출 파일 저장\n",
        "submission['Inhibition'] = preds\n",
        "submission.to_csv('submission_quantile_optuna.csv', index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T00:27:50.899289Z",
          "iopub.execute_input": "2025-07-03T00:27:50.899977Z",
          "iopub.status.idle": "2025-07-03T00:43:18.176339Z",
          "shell.execute_reply.started": "2025-07-03T00:27:50.899949Z",
          "shell.execute_reply": "2025-07-03T00:43:18.175635Z"
        },
        "id": "np_DdRnp4RQz",
        "outputId": "5ef09c1a-46dc-4292-857c-4fda4b5c838c"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[I 2025-07-03 00:27:52,887] A new study created in memory with name: no-name-c37ab2a4-a839-4298-96bf-dde3590657e3\n[I 2025-07-03 00:28:24,164] Trial 0 finished with value: 34.22000190910138 and parameters: {'alpha': 0.8761416252304671}. Best is trial 0 with value: 34.22000190910138.\n[I 2025-07-03 00:28:55,492] Trial 1 finished with value: 26.70219773843961 and parameters: {'alpha': 0.7874675139378836}. Best is trial 1 with value: 26.70219773843961.\n[I 2025-07-03 00:29:26,922] Trial 2 finished with value: 41.47617704908539 and parameters: {'alpha': 0.9357641087243449}. Best is trial 1 with value: 26.70219773843961.\n[I 2025-07-03 00:29:58,094] Trial 3 finished with value: 37.85524721010392 and parameters: {'alpha': 0.9065100697258024}. Best is trial 1 with value: 26.70219773843961.\n[I 2025-07-03 00:30:28,825] Trial 4 finished with value: 36.18760556829085 and parameters: {'alpha': 0.8944308008570636}. Best is trial 1 with value: 26.70219773843961.\n[I 2025-07-03 00:30:59,231] Trial 5 finished with value: 27.445148487375025 and parameters: {'alpha': 0.7984586098623716}. Best is trial 1 with value: 26.70219773843961.\n[I 2025-07-03 00:31:29,722] Trial 6 finished with value: 25.81414071996545 and parameters: {'alpha': 0.7720766784886315}. Best is trial 6 with value: 25.81414071996545.\n[I 2025-07-03 00:32:00,280] Trial 7 finished with value: 27.95699708508739 and parameters: {'alpha': 0.8073048053581211}. Best is trial 6 with value: 25.81414071996545.\n[I 2025-07-03 00:32:30,930] Trial 8 finished with value: 34.157200069120314 and parameters: {'alpha': 0.875166349459087}. Best is trial 6 with value: 25.81414071996545.\n[I 2025-07-03 00:33:01,655] Trial 9 finished with value: 32.98030499464893 and parameters: {'alpha': 0.8630590135450942}. Best is trial 6 with value: 25.81414071996545.\n[I 2025-07-03 00:33:32,726] Trial 10 finished with value: 23.48513666649775 and parameters: {'alpha': 0.7156564327835898}. Best is trial 10 with value: 23.48513666649775.\n[I 2025-07-03 00:34:03,771] Trial 11 finished with value: 23.386574886270903 and parameters: {'alpha': 0.7124130960579617}. Best is trial 11 with value: 23.386574886270903.\n[I 2025-07-03 00:34:34,735] Trial 12 finished with value: 23.003326284775916 and parameters: {'alpha': 0.7030731325558534}. Best is trial 12 with value: 23.003326284775916.\n[I 2025-07-03 00:35:05,660] Trial 13 finished with value: 23.126720704610896 and parameters: {'alpha': 0.706933818664903}. Best is trial 12 with value: 23.003326284775916.\n[I 2025-07-03 00:35:35,919] Trial 14 finished with value: 24.613647161245108 and parameters: {'alpha': 0.7465036602047656}. Best is trial 12 with value: 23.003326284775916.\n[I 2025-07-03 00:36:06,172] Trial 15 finished with value: 22.901478277928305 and parameters: {'alpha': 0.7000582460103941}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:36:36,531] Trial 16 finished with value: 24.688375621489776 and parameters: {'alpha': 0.7481563654680752}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:37:06,827] Trial 17 finished with value: 31.06267127281233 and parameters: {'alpha': 0.8420251461616157}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:37:37,147] Trial 18 finished with value: 24.61237738555664 and parameters: {'alpha': 0.7462919858171572}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:38:07,422] Trial 19 finished with value: 25.40780656013515 and parameters: {'alpha': 0.7644511064487014}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:38:37,754] Trial 20 finished with value: 22.95893269802864 and parameters: {'alpha': 0.7012337667738227}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:39:07,947] Trial 21 finished with value: 23.974990421008897 and parameters: {'alpha': 0.7286362259296101}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:39:38,024] Trial 22 finished with value: 24.04676003228735 and parameters: {'alpha': 0.730737369538862}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:40:08,134] Trial 23 finished with value: 22.963813441145216 and parameters: {'alpha': 0.701502682326925}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:40:38,211] Trial 24 finished with value: 23.90963513944277 and parameters: {'alpha': 0.7273794299537402}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:41:08,339] Trial 25 finished with value: 25.550193936275633 and parameters: {'alpha': 0.7670694499464247}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:41:38,559] Trial 26 finished with value: 29.14636774427454 and parameters: {'alpha': 0.8256150528604422}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:42:08,693] Trial 27 finished with value: 22.940526291906345 and parameters: {'alpha': 0.7007487807483448}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:42:38,721] Trial 28 finished with value: 24.405603501613157 and parameters: {'alpha': 0.7392064859521698}. Best is trial 15 with value: 22.901478277928305.\n[I 2025-07-03 00:43:08,863] Trial 29 finished with value: 23.53462445559108 and parameters: {'alpha': 0.7181115191982398}. Best is trial 15 with value: 22.901478277928305.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# ✅ 데이터 로딩\n",
        "path = '/kaggle/input/drug-data'\n",
        "train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
        "submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "\n",
        "# ✅ RDKit 기반 특징 추출 (이전 단계 코드 활용)\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Crippen import MolLogP\n",
        "from rdkit.Chem.Descriptors import MolWt, NumRotatableBonds\n",
        "from rdkit.Chem.Lipinski import NumHDonors, NumHAcceptors\n",
        "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def extract_features(df):\n",
        "    mols = [Chem.MolFromSmiles(smi) for smi in df['Canonical_Smiles']]\n",
        "    features = {\n",
        "        'MolWt': [MolWt(mol) if mol else np.nan for mol in mols],\n",
        "        'LogP': [MolLogP(mol) if mol else np.nan for mol in mols],\n",
        "        'NumHDonors': [NumHDonors(mol) if mol else np.nan for mol in mols],\n",
        "        'NumHAcceptors': [NumHAcceptors(mol) if mol else np.nan for mol in mols],\n",
        "        'TPSA': [CalcTPSA(mol) if mol else np.nan for mol in mols],\n",
        "        'NumRotatableBonds': [NumRotatableBonds(mol) if mol else np.nan for mol in mols],\n",
        "        'RingCount': [mol.GetRingInfo().NumRings() if mol else np.nan for mol in mols]\n",
        "    }\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "X_train = extract_features(train)\n",
        "X_test = extract_features(test)\n",
        "y_train = train[\"Inhibition\"]\n",
        "\n",
        "# ✅ 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Sample Weight 정의 (높은 억제율에 더 높은 가중치 부여 예시)\n",
        "sample_weight = np.log1p(y_train)  # or y_train**1.5 등\n",
        "\n",
        "# ✅ 모델 학습 (5-Fold CV)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "preds = np.zeros(len(X_test))\n",
        "val_mae_list = []\n",
        "\n",
        "for train_idx, val_idx in kf.split(X_train_scaled):\n",
        "    X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "    w_tr = sample_weight.iloc[train_idx]\n",
        "\n",
        "    model = CatBoostRegressor(\n",
        "        iterations=2000,\n",
        "        learning_rate=0.03,\n",
        "        depth=6,\n",
        "        eval_metric='MAE',\n",
        "        early_stopping_rounds=100,\n",
        "        verbose=0,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    train_pool = Pool(X_tr, y_tr, weight=w_tr)\n",
        "    val_pool = Pool(X_val, y_val)\n",
        "    model.fit(train_pool, eval_set=val_pool)\n",
        "\n",
        "    val_pred = model.predict(X_val)\n",
        "    val_mae = mean_absolute_error(y_val, val_pred)\n",
        "    val_mae_list.append(val_mae)\n",
        "\n",
        "    preds += model.predict(X_test_scaled) / kf.n_splits\n",
        "\n",
        "# ✅ 성능 출력 및 제출 파일 저장\n",
        "print(f\"평균 MAE: {np.mean(val_mae_list):.4f}\")\n",
        "\n",
        "submission['Inhibition'] = preds\n",
        "submission.to_csv(\"submission_catboost_weighted.csv\", index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T01:20:15.17934Z",
          "iopub.execute_input": "2025-07-03T01:20:15.179948Z",
          "iopub.status.idle": "2025-07-03T01:20:19.51838Z",
          "shell.execute_reply.started": "2025-07-03T01:20:15.179914Z",
          "shell.execute_reply": "2025-07-03T01:20:19.517555Z"
        },
        "id": "S6mqwiCj4RQ0",
        "outputId": "ba0d55c8-b867-436a-8cf2-1e57e4e02999"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "평균 MAE: 21.8965\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.linear_model import Ridge\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# ✅ 데이터 로딩\n",
        "path = '/kaggle/input/drug-data'\n",
        "train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
        "submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\n",
        "\n",
        "# ✅ RDKit 기반 특징 추출\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Crippen import MolLogP\n",
        "from rdkit.Chem.Descriptors import MolWt, NumRotatableBonds\n",
        "from rdkit.Chem.Lipinski import NumHDonors, NumHAcceptors\n",
        "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
        "\n",
        "def extract_features(df):\n",
        "    mols = [Chem.MolFromSmiles(smi) for smi in df['Canonical_Smiles']]\n",
        "    features = {\n",
        "        'MolWt': [MolWt(mol) if mol else np.nan for mol in mols],\n",
        "        'LogP': [MolLogP(mol) if mol else np.nan for mol in mols],\n",
        "        'NumHDonors': [NumHDonors(mol) if mol else np.nan for mol in mols],\n",
        "        'NumHAcceptors': [NumHAcceptors(mol) if mol else np.nan for mol in mols],\n",
        "        'TPSA': [CalcTPSA(mol) if mol else np.nan for mol in mols],\n",
        "        'NumRotatableBonds': [NumRotatableBonds(mol) if mol else np.nan for mol in mols],\n",
        "        'RingCount': [mol.GetRingInfo().NumRings() if mol else np.nan for mol in mols]\n",
        "    }\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "X_train = extract_features(train)\n",
        "X_test = extract_features(test)\n",
        "y_train = train[\"Inhibition\"]\n",
        "\n",
        "# ✅ 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Sample Weight 정의\n",
        "sample_weight = np.log1p(y_train)\n",
        "\n",
        "# ✅ 수동 Stacking: Base 모델 예측값을 모아 최종 모델 학습\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_cat = np.zeros(len(X_train))\n",
        "oof_lgb = np.zeros(len(X_train))\n",
        "oof_ridge = np.zeros(len(X_train))\n",
        "test_cat = np.zeros(len(X_test))\n",
        "test_lgb = np.zeros(len(X_test))\n",
        "test_ridge = np.zeros(len(X_test))\n",
        "\n",
        "for train_idx, val_idx in kf.split(X_train_scaled):\n",
        "    X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "    w_tr = sample_weight.iloc[train_idx]\n",
        "\n",
        "    # CatBoost\n",
        "    cat = CatBoostRegressor(iterations=1500, learning_rate=0.03, depth=6, verbose=0, early_stopping_rounds=100, random_state=42)\n",
        "    cat.fit(Pool(X_tr, y_tr, weight=w_tr), eval_set=Pool(X_val, y_val))\n",
        "    oof_cat[val_idx] = cat.predict(X_val)\n",
        "    test_cat += cat.predict(X_test_scaled) / kf.n_splits\n",
        "\n",
        "    # LightGBM\n",
        "    lgb = LGBMRegressor(n_estimators=1500, learning_rate=0.03, max_depth=6, random_state=42)\n",
        "    lgb.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=0)\n",
        "    oof_lgb[val_idx] = lgb.predict(X_val)\n",
        "    test_lgb += lgb.predict(X_test_scaled) / kf.n_splits\n",
        "\n",
        "    # Ridge\n",
        "    ridge = Ridge(alpha=1.0)\n",
        "    ridge.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "    oof_ridge[val_idx] = ridge.predict(X_val)\n",
        "    test_ridge += ridge.predict(X_test_scaled) / kf.n_splits\n",
        "\n",
        "# ✅ 메타 모델 학습 (Linear Regression or Ridge)\n",
        "stacked_train = np.vstack([oof_cat, oof_lgb, oof_ridge]).T\n",
        "stacked_test = np.vstack([test_cat, test_lgb, test_ridge]).T\n",
        "\n",
        "meta_model = Ridge(alpha=1.0)\n",
        "meta_model.fit(stacked_train, y_train)\n",
        "final_preds = meta_model.predict(stacked_test)\n",
        "\n",
        "# ✅ 제출\n",
        "submission['Inhibition'] = final_preds\n",
        "submission.to_csv('submission_stacking_manual.csv', index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T01:22:06.654727Z",
          "iopub.execute_input": "2025-07-03T01:22:06.655573Z",
          "iopub.status.idle": "2025-07-03T01:22:12.881432Z",
          "shell.execute_reply.started": "2025-07-03T01:22:06.655543Z",
          "shell.execute_reply": "2025-07-03T01:22:12.880276Z"
        },
        "id": "KJo3sZB44RQ0",
        "outputId": "f3c79154-49fa-43a4-b74e-9975454c9b84"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n    ColabKernelApp.launch_instance()\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    result = self._run_cell(\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_163/3142171432.py\", line 6, in <cell line: 0>\n    from lightgbm import LGBMRegressor\n  File \"/usr/local/lib/python3.11/dist-packages/lightgbm/__init__.py\", line 11, in <module>\n    from .basic import Booster, Dataset, Sequence, register_logger\n  File \"/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\", line 29, in <module>\n    from .compat import (\n  File \"/usr/local/lib/python3.11/dist-packages/lightgbm/compat.py\", line 191, in <module>\n    import matplotlib  # noqa: F401\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ],
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_163/3142171432.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# LightGBM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mlgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0moof_lgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtest_lgb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'"
          ],
          "ename": "TypeError",
          "evalue": "LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    }
  ]
}