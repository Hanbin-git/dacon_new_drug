{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1517eju8eSyx3hqGDagRKuvI3SAD2Pq4I",
      "authorship_tag": "ABX9TyOKE9M0pwuNjr8i1ccXdZ86",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/dacon_new_drug/blob/main/20250710_2%EB%B2%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkNYexTpu1Ri",
        "outputId": "e7654977-53cd-4f36-8812-a808345346b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o \"/content/drive/MyDrive/data.zip\" -d \"/content/data_1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbgux4TZvMOS",
        "outputId": "7b01b011-38a6-4f74-8e14-a48a52036027"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/data.zip\n",
            "  inflating: /content/data_1/sample_submission.csv  \n",
            "  inflating: /content/data_1/test.csv  \n",
            "  inflating: /content/data_1/train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# ✅ 초기 환경 설정 및 라이브러리 설치 (가장 먼저 실행)\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. pip 캐시를 모두 비웁니다.\n",
        "print(\"Clearing pip cache...\")\n",
        "!pip cache purge\n",
        "\n",
        "# 2. numpy와 scikit-learn 관련 패키지를 강제로 제거합니다.\n",
        "print(\"Uninstalling numpy and scikit-learn related packages...\")\n",
        "!pip freeze | grep -E 'numpy|scikit-learn' | xargs -n 1 pip uninstall -y\n",
        "\n",
        "# 3. Colab 기본 라이브러리 (TensorFlow, Numba 등)와 호환되는 특정 버전의 numpy와 scikit-learn을 설치합니다.\n",
        "#    numpy를 1.26.x 대로 낮춰서 시도합니다.\n",
        "print(\"Installing compatible versions of numpy and scikit-learn (attempting numpy 1.26.x)...\")\n",
        "!pip install numpy==1.26.4 scikit-learn==1.6.0 --no-cache-dir --quiet\n",
        "\n",
        "# 4. 나머지 필요한 라이브러리들을 설치합니다.\n",
        "print(\"Installing other necessary libraries...\")\n",
        "!pip install rdkit-pypi catboost xgboost lightgbm optuna --no-cache-dir --quiet\n",
        "\n",
        "# 5. 파이썬 런타임을 강제로 재시작합니다. (가장 중요!)\n",
        "print(\"Forcing runtime restart... Please wait a few seconds for reconnection.\")\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "\n",
        "# =============================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CONAz5AYLqdW",
        "outputId": "b01ba988-f170-410b-f7ab-2f58d496fcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing pip cache...\n",
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "Uninstalling numpy and scikit-learn related packages...\n",
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: scikit-learn 1.6.0\n",
            "Uninstalling scikit-learn-1.6.0:\n",
            "  Successfully uninstalled scikit-learn-1.6.0\n",
            "Installing compatible versions of numpy and scikit-learn (attempting numpy 1.26.x)...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m267.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mInstalling other necessary libraries...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import os\n",
        "\n",
        "# # ✅ Colab 경로\n",
        "# extract_path = \"/content/data_1\"\n",
        "# def get_path(filename):\n",
        "#     return os.path.join(extract_path, filename)\n",
        "\n",
        "# # ✅ 데이터 불러오기\n",
        "# train = pd.read_csv(get_path(\"train.csv\"))\n",
        "# test = pd.read_csv(get_path(\"test.csv\"))\n",
        "\n",
        "# # ✅ 컬럼 확인\n",
        "# print(\"✅ [train.csv] 컬럼 목록:\")\n",
        "# print(train.columns.tolist())\n",
        "\n",
        "# print(\"\\n✅ [test.csv] 컬럼 목록:\")\n",
        "# print(test.columns.tolist())\n",
        "\n",
        "# # ✅ 샘플 데이터 미리 보기\n",
        "# print(\"\\n✅ [train.csv] 데이터 샘플:\")\n",
        "# print(train.head())\n",
        "\n",
        "# print(\"\\n✅ [test.csv] 데이터 샘플:\")\n",
        "# print(test.head())\n"
      ],
      "metadata": {
        "id": "XyOM1rGbzY9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ✅ import\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors, Crippen, Lipinski, rdMolDescriptors, AllChem\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from catboost import CatBoostRegressor, Pool\n",
        "# from lightgbm import LGBMRegressor\n",
        "# from xgboost import XGBRegressor\n",
        "# from sklearn.linear_model import Ridge\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# # ✅ 경로 설정 (Colab 환경)\n",
        "# extract_path = \"/content/data_1\"\n",
        "# def get_path(filename):\n",
        "#     return os.path.join(extract_path, filename)\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# train = pd.read_csv(get_path(\"train.csv\"))\n",
        "# test = pd.read_csv(get_path(\"test.csv\"))\n",
        "# submission = pd.read_csv(get_path(\"sample_submission.csv\"))\n",
        "\n",
        "# # ✅ RDKit Feature 추출\n",
        "# def extract_rdkit_features(df):\n",
        "#     mols = [Chem.MolFromSmiles(smi) for smi in df['Canonical_Smiles']]\n",
        "#     features = {\n",
        "#         'MolWt': [Descriptors.MolWt(mol) if mol else np.nan for mol in mols],\n",
        "#         'LogP': [Crippen.MolLogP(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumHDonors': [Lipinski.NumHDonors(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumHAcceptors': [Lipinski.NumHAcceptors(mol) if mol else np.nan for mol in mols],\n",
        "#         'TPSA': [rdMolDescriptors.CalcTPSA(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumRotatableBonds': [Descriptors.NumRotatableBonds(mol) if mol else np.nan for mol in mols],\n",
        "#         'RingCount': [mol.GetRingInfo().NumRings() if mol else np.nan for mol in mols],\n",
        "#         'HeavyAtomCount': [mol.GetNumHeavyAtoms() if mol else np.nan for mol in mols],\n",
        "#         'FractionCSP3': [rdMolDescriptors.CalcFractionCSP3(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumAliphaticRings': [rdMolDescriptors.CalcNumAliphaticRings(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumAromaticRings': [rdMolDescriptors.CalcNumAromaticRings(mol) if mol else np.nan for mol in mols]\n",
        "#     }\n",
        "#     return pd.DataFrame(features)\n",
        "\n",
        "# # ✅ Morgan Fingerprint 추출 (2048-bit)\n",
        "# def get_morgan_fingerprint(smiles, radius=2, nBits=2048):\n",
        "#     mol = Chem.MolFromSmiles(smiles)\n",
        "#     if mol:\n",
        "#         fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits)\n",
        "#         return np.array(fp)\n",
        "#     else:\n",
        "#         return np.zeros(nBits)\n",
        "\n",
        "# def extract_morgan_df(df, nBits=2048):\n",
        "#     fps = df['Canonical_Smiles'].apply(lambda x: get_morgan_fingerprint(x, nBits=nBits))\n",
        "#     return pd.DataFrame(fps.tolist(), columns=[f'MFP_{i}' for i in range(nBits)])\n",
        "\n",
        "# # ✅ Feature 생성\n",
        "# X_train_rdkit = extract_rdkit_features(train)\n",
        "# X_test_rdkit = extract_rdkit_features(test)\n",
        "# X_train_morgan = extract_morgan_df(train)\n",
        "# X_test_morgan = extract_morgan_df(test)\n",
        "\n",
        "# # ✅ 결합\n",
        "# X_train = pd.concat([X_train_rdkit, X_train_morgan], axis=1)\n",
        "# X_test = pd.concat([X_test_rdkit, X_test_morgan], axis=1)\n",
        "# y_train = train[\"Inhibition\"]\n",
        "\n",
        "# # ✅ 결측치 처리\n",
        "# X_train.fillna(0, inplace=True)\n",
        "# X_test.fillna(0, inplace=True)\n",
        "\n",
        "# # ✅ 정규화\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "# X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# # ✅ Sample Weight\n",
        "# sample_weight = np.log1p(y_train)\n",
        "\n",
        "# # ✅ Stacking 앙상블\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# oof_cat = np.zeros(len(X_train))\n",
        "# oof_lgb = np.zeros(len(X_train))\n",
        "# oof_xgb = np.zeros(len(X_train))\n",
        "# test_cat = np.zeros(len(X_test))\n",
        "# test_lgb = np.zeros(len(X_test))\n",
        "# test_xgb = np.zeros(len(X_test))\n",
        "\n",
        "# for train_idx, val_idx in kf.split(X_train_df):\n",
        "#     X_tr, X_val = X_train_df.iloc[train_idx], X_train_df.iloc[val_idx]\n",
        "#     y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "#     w_tr = sample_weight.iloc[train_idx]\n",
        "\n",
        "#     # CatBoost\n",
        "#     cat = CatBoostRegressor(iterations=1500, learning_rate=0.03, depth=6,\n",
        "#                             verbose=0, early_stopping_rounds=100, random_state=42)\n",
        "#     cat.fit(Pool(X_tr, y_tr, weight=w_tr), eval_set=Pool(X_val, y_val))\n",
        "#     oof_cat[val_idx] = cat.predict(X_val)\n",
        "#     test_cat += cat.predict(X_test_df) / kf.n_splits\n",
        "\n",
        "#     # LightGBM\n",
        "#     lgb = LGBMRegressor(n_estimators=1500, learning_rate=0.03, max_depth=6, random_state=42)\n",
        "#     lgb.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "#     oof_lgb[val_idx] = lgb.predict(X_val)\n",
        "#     test_lgb += lgb.predict(X_test_df) / kf.n_splits\n",
        "\n",
        "#     # XGBoost\n",
        "#     xgb = XGBRegressor(n_estimators=1500, learning_rate=0.03, max_depth=6, random_state=42)\n",
        "#     xgb.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "#     oof_xgb[val_idx] = xgb.predict(X_val)\n",
        "#     test_xgb += xgb.predict(X_test_df) / kf.n_splits\n",
        "\n",
        "# # ✅ 메타 모델\n",
        "# stacked_train = np.vstack([oof_cat, oof_lgb, oof_xgb]).T\n",
        "# stacked_test = np.vstack([test_cat, test_lgb, test_xgb]).T\n",
        "# meta_model = Ridge(alpha=1.0)\n",
        "# meta_model.fit(stacked_train, y_train)\n",
        "# final_preds = meta_model.predict(stacked_test)\n",
        "\n",
        "# # ✅ 제출 파일 저장\n",
        "# submission['Inhibition'] = final_preds\n",
        "# submission.to_csv('submission_stacking_rdkit_morgan.csv', index=False)\n",
        "# print(\"✅ 'submission_stacking_rdkit_morgan.csv' 생성 완료!\")\n"
      ],
      "metadata": {
        "id": "LzHmMssTzIf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors, Crippen, Lipinski, rdMolDescriptors, AllChem\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from catboost import CatBoostRegressor, Pool\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# extract_path = \"/content/data_1\"  # Colab 기준\n",
        "# train = pd.read_csv(os.path.join(extract_path, \"train.csv\"))\n",
        "# test = pd.read_csv(os.path.join(extract_path, \"test.csv\"))\n",
        "# submission = pd.read_csv(os.path.join(extract_path, \"sample_submission.csv\"))\n",
        "\n",
        "# # ✅ RDKit 기반 화학 특성 추출 (13개 내외)\n",
        "# def extract_physchem_features(df):\n",
        "#     mols = [Chem.MolFromSmiles(smi) for smi in df['Canonical_Smiles']]\n",
        "#     features = {\n",
        "#         'MolWt': [Descriptors.MolWt(mol) if mol else np.nan for mol in mols],\n",
        "#         'LogP': [Crippen.MolLogP(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumHDonors': [Lipinski.NumHDonors(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumHAcceptors': [Lipinski.NumHAcceptors(mol) if mol else np.nan for mol in mols],\n",
        "#         'TPSA': [rdMolDescriptors.CalcTPSA(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumRotatableBonds': [Descriptors.NumRotatableBonds(mol) if mol else np.nan for mol in mols],\n",
        "#         'RingCount': [mol.GetRingInfo().NumRings() if mol else np.nan for mol in mols],\n",
        "#         'HeavyAtomCount': [mol.GetNumHeavyAtoms() if mol else np.nan for mol in mols],\n",
        "#         'FractionCSP3': [rdMolDescriptors.CalcFractionCSP3(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumAliphaticRings': [rdMolDescriptors.CalcNumAliphaticRings(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumAromaticRings': [rdMolDescriptors.CalcNumAromaticRings(mol) if mol else np.nan for mol in mols],\n",
        "#     }\n",
        "#     return pd.DataFrame(features)\n",
        "\n",
        "# # ✅ Morgan Fingerprint (2048 bit)\n",
        "# def get_morgan_fp(smiles, radius=2, nBits=2048):\n",
        "#     mol = Chem.MolFromSmiles(smiles)\n",
        "#     if mol:\n",
        "#         return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits))\n",
        "#     else:\n",
        "#         return np.zeros(nBits)\n",
        "\n",
        "# def extract_morgan_df(df, nBits=2048):\n",
        "#     fps = df['Canonical_Smiles'].apply(lambda x: get_morgan_fp(x, nBits=nBits))\n",
        "#     return pd.DataFrame(fps.tolist(), columns=[f'MFP_{i}' for i in range(nBits)])\n",
        "\n",
        "# # ✅ 피처 생성\n",
        "# X_train_phys = extract_physchem_features(train)\n",
        "# X_test_phys = extract_physchem_features(test)\n",
        "# X_train_fp = extract_morgan_df(train)\n",
        "# X_test_fp = extract_morgan_df(test)\n",
        "\n",
        "# # ✅ 피처 결합\n",
        "# X_train = pd.concat([X_train_phys, X_train_fp], axis=1)\n",
        "# X_test = pd.concat([X_test_phys, X_test_fp], axis=1)\n",
        "# y_train = train[\"Inhibition\"]\n",
        "\n",
        "# # ✅ 정규화\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # ✅ Sample Weighting (log scale)\n",
        "# sample_weight = np.log1p(y_train)\n",
        "\n",
        "# # ✅ CatBoost 학습\n",
        "# model = CatBoostRegressor(\n",
        "#     iterations=1500,\n",
        "#     learning_rate=0.03,\n",
        "#     depth=6,\n",
        "#     loss_function='RMSE',\n",
        "#     early_stopping_rounds=100,\n",
        "#     verbose=100,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# model.fit(Pool(X_train_scaled, y_train, weight=sample_weight))\n",
        "# preds = model.predict(X_test_scaled)\n",
        "\n",
        "# # ✅ 제출 파일 저장\n",
        "# submission[\"Inhibition\"] = preds\n",
        "# submission.to_csv(\"submission_catboost_morgan_physchem13.csv\", index=False)\n",
        "# print(\"✅ 'submission_catboost_morgan_physchem13.csv' 저장 완료\")\n"
      ],
      "metadata": {
        "id": "vA3vZ_yF3LLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ✅ 라이브러리\n",
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors, Crippen, Lipinski, rdMolDescriptors, AllChem\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.linear_model import Ridge\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# from catboost import CatBoostRegressor, Pool\n",
        "# from lightgbm import LGBMRegressor\n",
        "# from xgboost import XGBRegressor\n",
        "\n",
        "# # ✅ 경로 설정 (Colab 기준)\n",
        "# extract_path = \"/content/data_1\"\n",
        "# def get_path(filename): return os.path.join(extract_path, filename)\n",
        "\n",
        "# train = pd.read_csv(get_path(\"train.csv\"))\n",
        "# test = pd.read_csv(get_path(\"test.csv\"))\n",
        "# submission = pd.read_csv(get_path(\"sample_submission.csv\"))\n",
        "\n",
        "# # ✅ RDKit 기반 분자 특성 추출\n",
        "# def extract_rdkit_features(df):\n",
        "#     mols = [Chem.MolFromSmiles(smi) for smi in df['Canonical_Smiles']]\n",
        "#     features = {\n",
        "#         'MolWt': [Descriptors.MolWt(mol) if mol else np.nan for mol in mols],\n",
        "#         'LogP': [Crippen.MolLogP(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumHDonors': [Lipinski.NumHDonors(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumHAcceptors': [Lipinski.NumHAcceptors(mol) if mol else np.nan for mol in mols],\n",
        "#         'TPSA': [rdMolDescriptors.CalcTPSA(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumRotatableBonds': [Descriptors.NumRotatableBonds(mol) if mol else np.nan for mol in mols],\n",
        "#         'RingCount': [mol.GetRingInfo().NumRings() if mol else np.nan for mol in mols],\n",
        "#         'HeavyAtomCount': [mol.GetNumHeavyAtoms() if mol else np.nan for mol in mols],\n",
        "#         'FractionCSP3': [rdMolDescriptors.CalcFractionCSP3(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumAliphaticRings': [rdMolDescriptors.CalcNumAliphaticRings(mol) if mol else np.nan for mol in mols],\n",
        "#         'NumAromaticRings': [rdMolDescriptors.CalcNumAromaticRings(mol) if mol else np.nan for mol in mols]\n",
        "#     }\n",
        "#     return pd.DataFrame(features)\n",
        "\n",
        "# # ✅ Morgan Fingerprint\n",
        "# def get_morgan_fingerprint(smiles, radius=2, nBits=2048):\n",
        "#     mol = Chem.MolFromSmiles(smiles)\n",
        "#     if mol:\n",
        "#         fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits)\n",
        "#         return np.array(fp)\n",
        "#     else:\n",
        "#         return np.zeros(nBits)\n",
        "\n",
        "# def extract_morgan_df(df, nBits=2048):\n",
        "#     fps = df['Canonical_Smiles'].apply(lambda x: get_morgan_fingerprint(x, nBits=nBits))\n",
        "#     return pd.DataFrame(fps.tolist(), columns=[f'MFP_{i}' for i in range(nBits)])\n",
        "\n",
        "# # ✅ Feature 결합\n",
        "# X_train_rdkit = extract_rdkit_features(train)\n",
        "# X_test_rdkit = extract_rdkit_features(test)\n",
        "# X_train_morgan = extract_morgan_df(train)\n",
        "# X_test_morgan = extract_morgan_df(test)\n",
        "\n",
        "# X_train = pd.concat([X_train_rdkit, X_train_morgan], axis=1)\n",
        "# X_test = pd.concat([X_test_rdkit, X_test_morgan], axis=1)\n",
        "# y_train = train[\"Inhibition\"]\n",
        "\n",
        "# # ✅ 정규화\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "# X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "# X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# # ✅ Sample Weight\n",
        "# sample_weight = np.log1p(y_train)\n",
        "\n",
        "# # ✅ 앙상블 초기화\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# oof_cat = np.zeros(len(X_train))\n",
        "# oof_lgb = np.zeros(len(X_train))\n",
        "# oof_xgb = np.zeros(len(X_train))\n",
        "# test_cat = np.zeros(len(X_test))\n",
        "# test_lgb = np.zeros(len(X_test))\n",
        "# test_xgb = np.zeros(len(X_test))\n",
        "\n",
        "# # ✅ 교차검증 모델 학습\n",
        "# for train_idx, val_idx in kf.split(X_train_df):\n",
        "#     X_tr, X_val = X_train_df.iloc[train_idx], X_train_df.iloc[val_idx]\n",
        "#     y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "#     w_tr = sample_weight.iloc[train_idx]\n",
        "\n",
        "#     # ✅ CatBoost (GPU)\n",
        "#     cat = CatBoostRegressor(\n",
        "#         iterations=1500, learning_rate=0.03, depth=6, verbose=0,\n",
        "#         early_stopping_rounds=100, random_state=42, task_type='GPU'\n",
        "#     )\n",
        "#     cat.fit(Pool(X_tr, y_tr, weight=w_tr), eval_set=Pool(X_val, y_val))\n",
        "#     oof_cat[val_idx] = cat.predict(X_val)\n",
        "#     test_cat += cat.predict(X_test_df) / kf.n_splits\n",
        "\n",
        "#     # ✅ LightGBM (GPU)\n",
        "#     lgb = LGBMRegressor(\n",
        "#         n_estimators=1500, learning_rate=0.03, max_depth=6, random_state=42,\n",
        "#         device='gpu'\n",
        "#     )\n",
        "#     lgb.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "#     oof_lgb[val_idx] = lgb.predict(X_val)\n",
        "#     test_lgb += lgb.predict(X_test_df) / kf.n_splits\n",
        "\n",
        "#     # ✅ XGBoost (GPU)\n",
        "#     xgb = XGBRegressor(\n",
        "#         n_estimators=1500, learning_rate=0.03, max_depth=6, random_state=42,\n",
        "#         tree_method='gpu_hist', predictor='gpu_predictor'\n",
        "#     )\n",
        "#     xgb.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "#     oof_xgb[val_idx] = xgb.predict(X_val)\n",
        "#     test_xgb += xgb.predict(X_test_df) / kf.n_splits\n",
        "\n",
        "# # ✅ 메타 모델 (Ridge)\n",
        "# stacked_train = np.vstack([oof_cat, oof_lgb, oof_xgb]).T\n",
        "# stacked_test = np.vstack([test_cat, test_lgb, test_xgb]).T\n",
        "# meta_model = Ridge(alpha=1.0)\n",
        "# meta_model.fit(stacked_train, y_train)\n",
        "# final_preds = meta_model.predict(stacked_test)\n",
        "\n",
        "# # ✅ 성능 평가\n",
        "# rmse = np.sqrt(mean_squared_error(y_train, meta_model.predict(stacked_train)))\n",
        "# mae = mean_absolute_error(y_train, meta_model.predict(stacked_train))\n",
        "# print(f\"✅ Meta Model RMSE: {rmse:.4f}\")\n",
        "# print(f\"✅ Meta Model MAE : {mae:.4f}\")\n",
        "\n",
        "# # ✅ 제출\n",
        "# submission['Inhibition'] = final_preds\n",
        "# submission.to_csv(\"submission_stacking_rdkit_morgan.csv\", index=False)\n",
        "# print(\"✅ 'submission_stacking_rdkit_morgan.csv' 저장 완료!\")\n"
      ],
      "metadata": {
        "id": "BUCB2KpM3yI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 전체 실행 코드\n",
        "import os, gc, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "import optuna\n",
        "\n",
        "# ✅ 경로 설정\n",
        "extract_path = \"/content/data_1\"\n",
        "def get_path(filename): return os.path.join(extract_path, filename)\n",
        "train = pd.read_csv(get_path(\"train.csv\"))\n",
        "test = pd.read_csv(get_path(\"test.csv\"))\n",
        "submission = pd.read_csv(get_path(\"sample_submission.csv\"))\n",
        "\n",
        "# ✅ RDKit Feature 생성\n",
        "def calc_physchem(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None: return [np.nan] * 10\n",
        "    return [\n",
        "        Descriptors.MolWt(mol), Descriptors.MolLogP(mol), Descriptors.NumHDonors(mol),\n",
        "        Descriptors.NumHAcceptors(mol), Descriptors.TPSA(mol), Descriptors.NumRotatableBonds(mol),\n",
        "        Descriptors.RingCount(mol), Descriptors.FractionCSP3(mol),\n",
        "        Descriptors.HeavyAtomCount(mol), Descriptors.MolMR(mol)\n",
        "    ]\n",
        "\n",
        "physchem_cols = ['MolWt','LogP','HDonors','HAcceptors','TPSA','RotBonds','Rings','CSP3','HeavyAtoms','MR']\n",
        "train_physchem = pd.DataFrame([calc_physchem(smi) for smi in train['Canonical_Smiles']], columns=physchem_cols)\n",
        "test_physchem = pd.DataFrame([calc_physchem(smi) for smi in test['Canonical_Smiles']], columns=physchem_cols)\n",
        "\n",
        "# ✅ Morgan Fingerprints\n",
        "def morgan_fp(smiles, radius=2, nBits=1024):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits) if mol else [0]*nBits\n",
        "\n",
        "train_morgan = np.array([morgan_fp(smi) for smi in train['Canonical_Smiles']])\n",
        "test_morgan = np.array([morgan_fp(smi) for smi in test['Canonical_Smiles']])\n",
        "\n",
        "# ✅ Feature 결합 + 정규화\n",
        "X_train = np.hstack([train_physchem.values, train_morgan])\n",
        "X_test = np.hstack([test_physchem.values, test_morgan])\n",
        "y_train = train[\"Inhibition\"].values\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ✅ CatBoost Optuna 튜닝\n",
        "def objective_catboost(trial):\n",
        "    model = CatBoostRegressor(\n",
        "        iterations=trial.suggest_int(\"iterations\", 300, 700),\n",
        "        depth=trial.suggest_int(\"depth\", 4, 10),\n",
        "        learning_rate=trial.suggest_float(\"lr\", 0.01, 0.2),\n",
        "        l2_leaf_reg=trial.suggest_float(\"l2\", 1e-3, 10.0),\n",
        "        loss_function=\"RMSE\", task_type=\"GPU\", verbose=0\n",
        "    )\n",
        "    scores = []\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    for tr_idx, val_idx in kf.split(X_train):\n",
        "        model.fit(X_train[tr_idx], y_train[tr_idx])\n",
        "        pred = model.predict(X_train[val_idx])\n",
        "        scores.append(np.sqrt(mean_squared_error(y_train[val_idx], pred)))\n",
        "    return np.mean(scores)\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_catboost, n_trials=20)\n",
        "best_cat_params = study.best_trial.params\n",
        "best_cat_params_fixed = {\n",
        "    'iterations': best_cat_params['iterations'],\n",
        "    'depth': best_cat_params['depth'],\n",
        "    'learning_rate': best_cat_params['lr'],\n",
        "    'l2_leaf_reg': best_cat_params['l2']\n",
        "}\n",
        "\n",
        "# ✅ Base 모델 학습 + OOF\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_train = np.zeros((X_train.shape[0], 3))\n",
        "oof_test = np.zeros((X_test.shape[0], 3))\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "    print(f\"📦 Fold {fold+1}\")\n",
        "    cat = CatBoostRegressor(**best_cat_params_fixed, loss_function=\"RMSE\", task_type=\"GPU\", verbose=0)\n",
        "    cat.fit(X_train[tr_idx], y_train[tr_idx])\n",
        "    oof_train[val_idx, 0] = cat.predict(X_train[val_idx])\n",
        "    oof_test[:, 0] += cat.predict(X_test) / kf.n_splits\n",
        "\n",
        "    lgb = LGBMRegressor(device='gpu', learning_rate=0.05, n_estimators=500)\n",
        "    lgb.fit(X_train[tr_idx], y_train[tr_idx])\n",
        "    oof_train[val_idx, 1] = lgb.predict(X_train[val_idx])\n",
        "    oof_test[:, 1] += lgb.predict(X_test) / kf.n_splits\n",
        "\n",
        "    xgb = XGBRegressor(tree_method='gpu_hist', learning_rate=0.05, n_estimators=500)\n",
        "    xgb.fit(X_train[tr_idx], y_train[tr_idx])\n",
        "    oof_train[val_idx, 2] = xgb.predict(X_train[val_idx])\n",
        "    oof_test[:, 2] += xgb.predict(X_test) / kf.n_splits\n",
        "\n",
        "# ✅ Ridge Meta 모델 튜닝\n",
        "def objective_meta(trial):\n",
        "    alpha = trial.suggest_float(\"alpha\", 0.01, 10.0)\n",
        "    model = Ridge(alpha=alpha)\n",
        "    scores = []\n",
        "    kf_meta = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    for tr_meta, val_meta in kf_meta.split(oof_train):\n",
        "        model.fit(oof_train[tr_meta], y_train[tr_meta])\n",
        "        pred = model.predict(oof_train[val_meta])\n",
        "        scores.append(np.sqrt(mean_squared_error(y_train[val_meta], pred)))\n",
        "    return np.mean(scores)\n",
        "\n",
        "meta_study = optuna.create_study(direction=\"minimize\")\n",
        "meta_study.optimize(objective_meta, n_trials=20)\n",
        "best_alpha = meta_study.best_params[\"alpha\"]\n",
        "\n",
        "# ✅ 최종 예측 및 저장\n",
        "meta_model = Ridge(alpha=best_alpha)\n",
        "meta_model.fit(oof_train, y_train)\n",
        "final_pred = meta_model.predict(oof_test)\n",
        "submission[\"Inhibition\"] = final_pred\n",
        "submission.to_csv(\"submission_stacking_optuna_ridge.csv\", index=False)\n",
        "print(\"✅ 저장 완료: submission_stacking_optuna_ridge.csv\")\n",
        "print(\"✅ Meta RMSE:\", mean_squared_error(y_train, meta_model.predict(oof_train), squared=False))\n",
        "print(\"✅ Meta MAE :\", mean_absolute_error(y_train, meta_model.predict(oof_train)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9MuvIpoO7x68",
        "outputId": "1d5049e2-f065-4d9d-b772-54df91ed3f14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-10 06:23:48,216] A new study created in memory with name: no-name-bdc6b571-86f5-4c35-b9fc-ee28c998e152\n",
            "[I 2025-07-10 06:24:19,228] Trial 0 finished with value: 25.042762396174243 and parameters: {'iterations': 681, 'depth': 8, 'lr': 0.09270997477968122, 'l2': 2.317004940100394}. Best is trial 0 with value: 25.042762396174243.\n",
            "[I 2025-07-10 06:25:22,599] Trial 1 finished with value: 24.09810198132386 and parameters: {'iterations': 528, 'depth': 10, 'lr': 0.021628934095191194, 'l2': 3.47308957048379}. Best is trial 1 with value: 24.09810198132386.\n",
            "[I 2025-07-10 06:25:28,752] Trial 2 finished with value: 23.94402793568152 and parameters: {'iterations': 336, 'depth': 7, 'lr': 0.10542357443836291, 'l2': 4.299417435894376}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:25:40,088] Trial 3 finished with value: 24.68024486252904 and parameters: {'iterations': 536, 'depth': 4, 'lr': 0.08941716103687852, 'l2': 3.3483199478494416}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:25:52,965] Trial 4 finished with value: 24.30519467354189 and parameters: {'iterations': 563, 'depth': 5, 'lr': 0.05981045382325988, 'l2': 5.684812479683683}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:27:11,729] Trial 5 finished with value: 24.384879123562637 and parameters: {'iterations': 631, 'depth': 10, 'lr': 0.045953196065635, 'l2': 5.591247703743996}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:27:18,204] Trial 6 finished with value: 24.388875633723075 and parameters: {'iterations': 449, 'depth': 6, 'lr': 0.15044743207920455, 'l2': 1.6788451828389832}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:28:24,380] Trial 7 finished with value: 24.475084699142354 and parameters: {'iterations': 520, 'depth': 10, 'lr': 0.08589522270908952, 'l2': 7.744609698664996}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:28:34,243] Trial 8 finished with value: 24.670565185460504 and parameters: {'iterations': 422, 'depth': 10, 'lr': 0.1876257375113267, 'l2': 3.9240695861617994}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:28:39,705] Trial 9 finished with value: 23.945138059924435 and parameters: {'iterations': 301, 'depth': 6, 'lr': 0.014023307487108113, 'l2': 1.1580294559668802}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:28:46,109] Trial 10 finished with value: 24.094367365225 and parameters: {'iterations': 312, 'depth': 8, 'lr': 0.13826266438387091, 'l2': 9.946013644446474}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:28:51,988] Trial 11 finished with value: 24.568910899955863 and parameters: {'iterations': 300, 'depth': 7, 'lr': 0.1398067849892959, 'l2': 0.12850048297159677}. Best is trial 2 with value: 23.94402793568152.\n",
            "[I 2025-07-10 06:28:58,028] Trial 12 finished with value: 23.86110805528389 and parameters: {'iterations': 375, 'depth': 6, 'lr': 0.020072350651208538, 'l2': 0.047800224439186856}. Best is trial 12 with value: 23.86110805528389.\n",
            "[I 2025-07-10 06:29:04,579] Trial 13 finished with value: 24.15649583953083 and parameters: {'iterations': 385, 'depth': 7, 'lr': 0.12008682828179423, 'l2': 7.194382670371861}. Best is trial 12 with value: 23.86110805528389.\n",
            "[I 2025-07-10 06:29:11,536] Trial 14 finished with value: 24.083974870582097 and parameters: {'iterations': 377, 'depth': 8, 'lr': 0.059124779434107246, 'l2': 0.5726862166117954}. Best is trial 12 with value: 23.86110805528389.\n",
            "[I 2025-07-10 06:29:17,427] Trial 15 finished with value: 24.42336496077678 and parameters: {'iterations': 357, 'depth': 6, 'lr': 0.18134180622308305, 'l2': 6.94178834413638}. Best is trial 12 with value: 23.86110805528389.\n",
            "[I 2025-07-10 06:29:23,153] Trial 16 finished with value: 24.198955641628398 and parameters: {'iterations': 454, 'depth': 4, 'lr': 0.1116553279218447, 'l2': 9.633890522795944}. Best is trial 12 with value: 23.86110805528389.\n",
            "[I 2025-07-10 06:29:29,469] Trial 17 finished with value: 23.781743518765783 and parameters: {'iterations': 349, 'depth': 7, 'lr': 0.03784647506192646, 'l2': 4.5239617757359705}. Best is trial 17 with value: 23.781743518765783.\n",
            "[I 2025-07-10 06:29:35,291] Trial 18 finished with value: 23.858030295201928 and parameters: {'iterations': 403, 'depth': 5, 'lr': 0.03535072857256803, 'l2': 2.3352869445819593}. Best is trial 17 with value: 23.781743518765783.\n",
            "[I 2025-07-10 06:29:41,385] Trial 19 finished with value: 23.88473764723051 and parameters: {'iterations': 420, 'depth': 5, 'lr': 0.04081825717034094, 'l2': 2.5799327863565655}. Best is trial 17 with value: 23.781743518765783.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Fold 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 3509\n",
            "[LightGBM] [Info] Number of data points in the train set: 1344, number of used features: 770\n",
            "[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-40GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 25 dense feature groups (0.04 MB) transferred to GPU in 0.001606 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 33.391242\n",
            "📦 Fold 2\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 3488\n",
            "[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 762\n",
            "[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-40GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 25 dense feature groups (0.04 MB) transferred to GPU in 0.001475 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 33.637152\n",
            "📦 Fold 3\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 3535\n",
            "[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 778\n",
            "[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-40GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 25 dense feature groups (0.04 MB) transferred to GPU in 0.001514 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 33.054065\n",
            "📦 Fold 4\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 3480\n",
            "[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 762\n",
            "[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-40GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 26 dense feature groups (0.04 MB) transferred to GPU in 0.001575 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 33.229167\n",
            "📦 Fold 5\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 3495\n",
            "[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 767\n",
            "[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-40GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 25 dense feature groups (0.04 MB) transferred to GPU in 0.001435 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 32.797655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-10 06:30:11,121] A new study created in memory with name: no-name-d0dcc222-88af-42df-ac3a-1e1acbe3848c\n",
            "[I 2025-07-10 06:30:11,143] Trial 0 finished with value: 23.906869532514445 and parameters: {'alpha': 4.880541781535753}. Best is trial 0 with value: 23.906869532514445.\n",
            "[I 2025-07-10 06:30:11,149] Trial 1 finished with value: 23.906865028066985 and parameters: {'alpha': 6.926444406041938}. Best is trial 1 with value: 23.906865028066985.\n",
            "[I 2025-07-10 06:30:11,155] Trial 2 finished with value: 23.906878425879146 and parameters: {'alpha': 0.8475071295655999}. Best is trial 1 with value: 23.906865028066985.\n",
            "[I 2025-07-10 06:30:11,160] Trial 3 finished with value: 23.906876238501354 and parameters: {'alpha': 1.8386833354763246}. Best is trial 1 with value: 23.906865028066985.\n",
            "[I 2025-07-10 06:30:11,166] Trial 4 finished with value: 23.906864502539012 and parameters: {'alpha': 7.165277276111415}. Best is trial 4 with value: 23.906864502539012.\n",
            "[I 2025-07-10 06:30:11,171] Trial 5 finished with value: 23.906876217651615 and parameters: {'alpha': 1.8481334948740784}. Best is trial 4 with value: 23.906864502539012.\n",
            "[I 2025-07-10 06:30:11,177] Trial 6 finished with value: 23.906871589982416 and parameters: {'alpha': 3.9467622935172035}. Best is trial 4 with value: 23.906864502539012.\n",
            "[I 2025-07-10 06:30:11,183] Trial 7 finished with value: 23.906859652808254 and parameters: {'alpha': 9.370683447197669}. Best is trial 7 with value: 23.906859652808254.\n",
            "[I 2025-07-10 06:30:11,188] Trial 8 finished with value: 23.90686690677782 and parameters: {'alpha': 6.072879890397285}. Best is trial 7 with value: 23.906859652808254.\n",
            "[I 2025-07-10 06:30:11,194] Trial 9 finished with value: 23.90686204725561 and parameters: {'alpha': 8.281500512486112}. Best is trial 7 with value: 23.906859652808254.\n",
            "[I 2025-07-10 06:30:11,203] Trial 10 finished with value: 23.90685903320016 and parameters: {'alpha': 9.652629275977777}. Best is trial 10 with value: 23.90685903320016.\n",
            "[I 2025-07-10 06:30:11,213] Trial 11 finished with value: 23.90685864149164 and parameters: {'alpha': 9.83089299905339}. Best is trial 11 with value: 23.90685864149164.\n",
            "[I 2025-07-10 06:30:11,222] Trial 12 finished with value: 23.906858681658324 and parameters: {'alpha': 9.812612680976216}. Best is trial 11 with value: 23.90685864149164.\n",
            "[I 2025-07-10 06:30:11,231] Trial 13 finished with value: 23.906858337207364 and parameters: {'alpha': 9.969381860472087}. Best is trial 13 with value: 23.906858337207364.\n",
            "[I 2025-07-10 06:30:11,240] Trial 14 finished with value: 23.906862322612167 and parameters: {'alpha': 8.156285779287035}. Best is trial 13 with value: 23.906858337207364.\n",
            "[I 2025-07-10 06:30:11,249] Trial 15 finished with value: 23.90686198346584 and parameters: {'alpha': 8.310509210353176}. Best is trial 13 with value: 23.906858337207364.\n",
            "[I 2025-07-10 06:30:11,259] Trial 16 finished with value: 23.90687280091311 and parameters: {'alpha': 3.3973919120845153}. Best is trial 13 with value: 23.906858337207364.\n",
            "[I 2025-07-10 06:30:11,268] Trial 17 finished with value: 23.906867615363623 and parameters: {'alpha': 5.751041552868246}. Best is trial 13 with value: 23.906858337207364.\n",
            "[I 2025-07-10 06:30:11,277] Trial 18 finished with value: 23.906861130777404 and parameters: {'alpha': 8.698314840413037}. Best is trial 13 with value: 23.906858337207364.\n",
            "[I 2025-07-10 06:30:11,286] Trial 19 finished with value: 23.906864216474673 and parameters: {'alpha': 7.29529517005337}. Best is trial 13 with value: 23.906858337207364.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 저장 완료: submission_stacking_optuna_ridge.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "got an unexpected keyword argument 'squared'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-4149971828.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission_stacking_optuna_ridge.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ 저장 완료: submission_stacking_optuna_ridge.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Meta RMSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Meta MAE :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Map *args/**kwargs to the function signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \"\"\"\n\u001b[0;32m-> 3195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3182\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3183\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3184\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m   3185\u001b[0m                     'got an unexpected keyword argument {arg!r}'.format(\n\u001b[1;32m   3186\u001b[0m                         arg=next(iter(kwargs))))\n",
            "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TjCzek4DNpQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}