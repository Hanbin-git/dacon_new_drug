{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12337654,
          "sourceType": "datasetVersion",
          "datasetId": 7777606
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook90dc24bd09",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/dacon_new_drug/blob/main/%EB%AA%A8%EB%8D%B8%EB%B3%84%20RMSE%20%ED%99%95%EC%9D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Ld6kjL9jED7u"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "biniroun_drug_data_path = kagglehub.dataset_download('biniroun/drug-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ELV6q1IZED7w"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle 노트북 상단에 RDKit 설치 명령어 추가\n",
        "!pip install rdkit-pypi"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T07:24:15.573696Z",
          "iopub.execute_input": "2025-07-01T07:24:15.574039Z",
          "iopub.status.idle": "2025-07-01T07:24:23.306506Z",
          "shell.execute_reply.started": "2025-07-01T07:24:15.574008Z",
          "shell.execute_reply": "2025-07-01T07:24:23.305287Z"
        },
        "id": "um-HaA12ED7x",
        "outputId": "18cdcb8b-83c3-407c-8411-783805b8144e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting rdkit-pypi\n  Downloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit-pypi) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit-pypi) (2024.2.0)\nDownloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2022.9.5\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 경우 다른 라이브러리도 함께 업그레이드/설치\n",
        "!pip install --upgrade scikit-learn pandas numpy xgboost lightgbm catboost"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T07:24:27.650505Z",
          "iopub.execute_input": "2025-07-01T07:24:27.651014Z",
          "iopub.status.idle": "2025-07-01T07:25:03.559822Z",
          "shell.execute_reply.started": "2025-07-01T07:24:27.650961Z",
          "shell.execute_reply": "2025-07-01T07:25:03.55847Z"
        },
        "id": "wJSCzqJEED7z",
        "outputId": "3f712d83-340f-45b3-d5ab-6a40e962eb08"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nCollecting pandas\n  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nCollecting numpy\n  Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nCollecting xgboost\n  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\nCollecting lightgbm\n  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\nRequirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.7.2)\nRequirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.0.9)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\nDownloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, pandas, xgboost, scikit-learn, lightgbm\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n  Attempting uninstall: xgboost\n    Found existing installation: xgboost 2.0.3\n    Uninstalling xgboost-2.0.3:\n      Successfully uninstalled xgboost-2.0.3\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 4.5.0\n    Uninstalling lightgbm-4.5.0:\n      Successfully uninstalled lightgbm-4.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.1 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.1 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.1 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.1 which is incompatible.\ncupy-cuda12x 13.4.1 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\ndask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\ncudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.1 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.0 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed lightgbm-4.6.0 numpy-2.3.1 pandas-2.3.0 scikit-learn-1.7.0 xgboost-3.0.2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 1. 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "# RDKit 라이브러리\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors # Descriptors 추가 임포트\n",
        "\n",
        "# Scikit-learn 라이브러리\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge # Stacking 메타 모델\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 부스팅 모델\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor # LightGBM 추가\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# 스태킹 앙상블\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "# 경고 메시지 무시 및 RDKit 에러 메시지 억제\n",
        "warnings.filterwarnings('ignore')\n",
        "from rdkit import rdBase\n",
        "rdBase.DisableLog('rdApp.error')\n",
        "\n",
        "print(f\"--- Kaggle 파이프라인 시작: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())} ---\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T07:25:08.851071Z",
          "iopub.execute_input": "2025-07-01T07:25:08.851452Z",
          "iopub.status.idle": "2025-07-01T07:25:14.986305Z",
          "shell.execute_reply.started": "2025-07-01T07:25:08.851419Z",
          "shell.execute_reply": "2025-07-01T07:25:14.984697Z"
        },
        "id": "r_8y2vOnED7z",
        "outputId": "d1025fdd-806e-4c0b-e9d8-33a9c6aec0bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--- Kaggle 파이프라인 시작: 2025-07-01 07:25:14 ---\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 2. 데이터 경로 설정 및 데이터 로드 (Kaggle 전용 경로)\n",
        "# 이 경로는 Kaggle에서 데이터셋을 추가했을 때의 기본 경로입니다.\n",
        "# 만약 대회 데이터셋 이름이 다르다면, data_path를 변경해야 합니다.\n",
        "# 예: data_path = \"/kaggle/input/dacon-cyp3a4-inhibition-prediction\"\n",
        "data_path = \"/kaggle/input/drug-data\" # 가정된 데이터셋 경로\n",
        "\n",
        "print(f\"데이터 로딩 중... 경로: {data_path}\")\n",
        "try:\n",
        "    train_df = pd.read_csv(f\"{data_path}/train.csv\")\n",
        "    test_df = pd.read_csv(f\"{data_path}/test.csv\")\n",
        "    submission_df = pd.read_csv(f\"{data_path}/sample_submission.csv\").copy() # .copy()를 통해 안전하게 작업\n",
        "    print(\"데이터 로드 완료.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: 파일을 찾을 수 없습니다. Kaggle 데이터셋 경로를 다시 확인해주세요: {data_path}\")\n",
        "    raise # 파일이 없으면 실행 중단\n",
        "\n",
        "# 컬럼명 앞뒤 공백 제거 (데이터 클리닝)\n",
        "train_df.columns = train_df.columns.str.strip()\n",
        "test_df.columns = test_df.columns.str.strip()\n",
        "submission_df.columns = submission_df.columns.str.strip()\n",
        "\n",
        "print(f\"훈련 데이터 Shape: {train_df.shape}\")\n",
        "print(f\"테스트 데이터 Shape: {test_df.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T07:25:37.647829Z",
          "iopub.execute_input": "2025-07-01T07:25:37.648669Z",
          "iopub.status.idle": "2025-07-01T07:25:37.689Z",
          "shell.execute_reply.started": "2025-07-01T07:25:37.648638Z",
          "shell.execute_reply": "2025-07-01T07:25:37.687584Z"
        },
        "id": "W9afHp25ED70",
        "outputId": "5f63afdb-bcf5-44a1-adb2-ee89007f6351"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "데이터 로딩 중... 경로: /kaggle/input/drug-data\n데이터 로드 완료.\n훈련 데이터 Shape: (1681, 3)\n테스트 데이터 Shape: (100, 2)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 3. 특성 추출 (Feature Engineering): 모든 RDKit Descriptors + Morgan Fingerprints\n",
        "def get_all_molecular_features(smiles_string, n_bits=2048, radius=2):\n",
        "    \"\"\"\n",
        "    SMILES 문자열로부터 모든 RDKit Descriptors와 Morgan Fingerprint를 추출합니다.\n",
        "    \"\"\"\n",
        "    mol = Chem.MolFromSmiles(str(smiles_string))\n",
        "    if mol is None:\n",
        "        # 분자 생성 실패 시, 모든 피처를 0으로 채운 배열 반환\n",
        "        num_descriptors = len(Descriptors._descList)\n",
        "        return np.zeros(num_descriptors + n_bits, dtype=float)\n",
        "\n",
        "    # RDKit Descriptors 추출\n",
        "    descriptor_values = []\n",
        "    for desc_name, desc_func in Descriptors._descList:\n",
        "        try:\n",
        "            val = desc_func(mol)\n",
        "            # NaN 또는 Inf 값 처리: 0으로 대체 (모델이 NaN/Inf를 처리하지 못할 경우)\n",
        "            if np.isnan(val) or np.isinf(val):\n",
        "                descriptor_values.append(0.0)\n",
        "            else:\n",
        "                descriptor_values.append(val)\n",
        "        except:\n",
        "            # 계산 중 오류 발생 시 0으로 대체\n",
        "            descriptor_values.append(0.0)\n",
        "\n",
        "    # Morgan Fingerprint 추출\n",
        "    try:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
        "        morgan_fp_values = np.array(fp, dtype=float)\n",
        "    except:\n",
        "        # Fingerprint 계산 오류 시 0으로 채운 배열 반환\n",
        "        morgan_fp_values = np.zeros(n_bits, dtype=float)\n",
        "\n",
        "    # 두 피처 세트를 결합하여 반환\n",
        "    return np.concatenate([descriptor_values, morgan_fp_values])\n",
        "\n",
        "print(\"\\n분자 특성 추출 시작 (모든 RDKit Descriptors + Morgan Fingerprints)...\")\n",
        "start_time_fe = time.time()\n",
        "\n",
        "# 훈련 및 테스트 데이터셋에 피처 추출 함수 적용\n",
        "train_features_raw = train_df['Canonical_Smiles'].apply(get_all_molecular_features)\n",
        "test_features_raw = test_df['Canonical_Smiles'].apply(get_all_molecular_features)\n",
        "\n",
        "# numpy 배열로 변환\n",
        "X = np.vstack(train_features_raw.values)\n",
        "X_test = np.vstack(test_features_raw.values)\n",
        "\n",
        "# 타겟 변수 log1p 변환 (RMSE 개선에 도움)\n",
        "y = np.log1p(train_df['Inhibition'])\n",
        "\n",
        "end_time_fe = time.time()\n",
        "print(f\"특성 추출 완료. 소요 시간: {(end_time_fe - start_time_fe):.2f} 초\")\n",
        "print(f\"특성 추출 후 훈련 데이터 피처 형태: {X.shape}\")\n",
        "print(f\"특성 추출 후 테스트 데이터 피처 형태: {X_test.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T07:28:45.319412Z",
          "iopub.execute_input": "2025-07-01T07:28:45.319752Z",
          "iopub.status.idle": "2025-07-01T07:29:10.955498Z",
          "shell.execute_reply.started": "2025-07-01T07:28:45.319728Z",
          "shell.execute_reply": "2025-07-01T07:29:10.954421Z"
        },
        "id": "fFBP5PmxED71",
        "outputId": "07dd226b-0033-4412-aedc-ffe7c0f0642b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n분자 특성 추출 시작 (모든 RDKit Descriptors + Morgan Fingerprints)...\n특성 추출 완료. 소요 시간: 25.63 초\n특성 추출 후 훈련 데이터 피처 형태: (1681, 2256)\n특성 추출 후 테스트 데이터 피처 형태: (100, 2256)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- 여기서부터 제안된 보완점 적용 ---\n",
        "# ==============================================================================\n",
        "\n",
        "# ✅ 4. 데이터 스케일링\n",
        "print(\"\\n데이터 스케일링 시작 (StandardScaler)...\")\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"데이터 스케일링 완료.\")\n",
        "\n",
        "# ✅ 5. 피처 선택 (VarianceThreshold) - 스케일링 후 적용\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "print(\"\\n피처 선택 시작 (VarianceThreshold)...\")\n",
        "# 분산이 0인 (모든 값이 동일한) 피처만 제거. 스케일링 후에도 분산이 0이면 정보가 없음.\n",
        "# threshold를 0.01 등으로 설정하여 분산이 매우 낮은 피처도 제거할 수 있으나,\n",
        "# 일단 0으로 시작하여 완전히 불필요한 피처만 제거하는 것이 안전합니다.\n",
        "selector = VarianceThreshold(threshold=0.0)\n",
        "X_final = selector.fit_transform(X_scaled)\n",
        "X_test_final = selector.transform(X_test_scaled)\n",
        "\n",
        "print(f\"피처 선택 전 훈련 데이터 형태: {X_scaled.shape}\")\n",
        "print(f\"피처 선택 후 훈련 데이터 형태: {X_final.shape}\")\n",
        "print(f\"제거된 피처 수: {X_scaled.shape[1] - X_final.shape[1]}\")\n",
        "print(\"피처 선택 완료.\")\n",
        "\n",
        "# 이제부터 모델 학습에는 X_final과 X_test_final을 사용합니다.\n",
        "# y는 log1p 변환된 상태로 사용합니다.\n",
        "# (이 코드 스니펫에는 모델 학습 부분이 포함되어 있지 않으므로, 다음 셀에서 이 변수들을 사용해야 합니다.)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T07:30:41.736849Z",
          "iopub.execute_input": "2025-07-01T07:30:41.737278Z",
          "iopub.status.idle": "2025-07-01T07:30:41.960191Z",
          "shell.execute_reply.started": "2025-07-01T07:30:41.737251Z",
          "shell.execute_reply": "2025-07-01T07:30:41.959135Z"
        },
        "id": "0NLJu_vTED71",
        "outputId": "de2e1ed1-051e-469b-b3fb-f8ce252842dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n데이터 스케일링 시작 (StandardScaler)...\n데이터 스케일링 완료.\n\n피처 선택 시작 (VarianceThreshold)...\n피처 선택 전 훈련 데이터 형태: (1681, 2256)\n피처 선택 후 훈련 데이터 형태: (1681, 2241)\n제거된 피처 수: 15\n피처 선택 완료.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- Subsequent Steps: Model Training, Stacking, Prediction, and Submission ---\n",
        "# --- (This code assumes X_final, X_test_final, and y are already prepared) ---\n",
        "# ==============================================================================\n",
        "\n",
        "# Ensure necessary libraries are imported (from your initial setup)\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from xgboost import XGBRegressor\n",
        "# from lightgbm import LGBMRegressor\n",
        "# from catboost import CatBoostRegressor\n",
        "# from sklearn.linear_model import Ridge\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import time\n",
        "\n",
        "# ✅ 5. 모델 학습 함수 (K-Fold 교차 검증 및 OOF/테스트 예측 생성)\n",
        "# This function should already be defined in your notebook from previous steps.\n",
        "# Re-including it here for context, but you don't need to define it again if it's already there.\n",
        "def train_and_predict_kfolds(model, model_name, X_data, y_data, X_test_data, n_splits=5, random_state=42):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    oof_preds = np.zeros(len(X_data))\n",
        "    test_preds = np.zeros(len(X_test_data))\n",
        "    fold_rmses = []\n",
        "\n",
        "    print(f\"  {model_name} 학습 시작 (K-Fold CV)...\")\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_data)):\n",
        "        start_fold_time = time.time()\n",
        "        X_train_fold, X_val_fold = X_data[train_idx], X_data[val_idx]\n",
        "        y_train_fold, y_val_fold = y_data.iloc[train_idx], y_data.iloc[val_idx] # y_data is pandas Series\n",
        "\n",
        "        # For CatBoost, if y_train_fold is a Series, it works fine.\n",
        "        # For others, numpy array conversion might be slightly faster but Series also works.\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "        # OOF 예측 (로그 스케일)\n",
        "        fold_val_preds = model.predict(X_val_fold)\n",
        "        oof_preds[val_idx] = fold_val_preds\n",
        "\n",
        "        # RMSE calculation (still in log scale for consistency with target 'y')\n",
        "        fold_rmse = np.sqrt(mean_squared_error(y_val_fold, fold_val_preds))\n",
        "        fold_rmses.append(fold_rmse)\n",
        "\n",
        "        # Test data prediction (still in log scale)\n",
        "        test_preds += model.predict(X_test_data) / kf.n_splits\n",
        "\n",
        "        end_fold_time = time.time()\n",
        "        print(f\"    Fold {fold+1}/{n_splits} 완료. RMSE: {fold_rmse:.4f}, 소요 시간: {(end_fold_time - start_fold_time):.2f} 초\")\n",
        "\n",
        "    avg_rmse = np.mean(fold_rmses)\n",
        "    print(f\"  ✅ {model_name} K-Fold 평균 RMSE (로그 스케일): {avg_rmse:.4f}\")\n",
        "    return test_preds, oof_preds # Returns predictions in log scale\n",
        "\n",
        "# ✅ 6. 기본 모델 정의 및 학습 (LGBM, XGBoost, CatBoost)\n",
        "print(\"\\n기본 모델 학습 시작...\")\n",
        "\n",
        "# LightGBM 모델 정의\n",
        "lgbm_model = LGBMRegressor(n_estimators=700, learning_rate=0.02, max_depth=8, random_state=42, n_jobs=-1, verbose=-1)\n",
        "# Pass X_final and X_test_final here\n",
        "lgbm_test_preds, lgbm_oof_preds = train_and_predict_kfolds(lgbm_model, \"LightGBM\", X_final, y, X_test_final)\n",
        "\n",
        "# XGBoost 모델 정의\n",
        "xgb_model = XGBRegressor(n_estimators=700, learning_rate=0.02, max_depth=8, random_state=42, n_jobs=-1, tree_method='hist')\n",
        "# Pass X_final and X_test_final here\n",
        "xgb_test_preds, xgb_oof_preds = train_and_predict_kfolds(xgb_model, \"XGBoost\", X_final, y, X_test_final)\n",
        "\n",
        "# CatBoost 모델 정의\n",
        "cat_model = CatBoostRegressor(iterations=700, learning_rate=0.02, depth=9, random_state=42, verbose=0, thread_count=-1)\n",
        "# Pass X_final and X_test_final here\n",
        "cat_test_preds, cat_oof_preds = train_and_predict_kfolds(cat_model, \"CatBoost\", X_final, y, X_test_final)\n",
        "\n",
        "print(\"\\n기본 모델 학습 및 예측 완료.\")\n",
        "\n",
        "# ✅ 7. Stacking 앙상블 (메타 모델 학습)\n",
        "print(\"\\nStacking 메타 모델 학습 시작...\")\n",
        "\n",
        "# Meta-model input data: OOF predictions from base models\n",
        "# Ensure the stacking input dimensions are correct (samples, num_base_models)\n",
        "stacked_X = np.vstack([lgbm_oof_preds, xgb_oof_preds, cat_oof_preds]).T\n",
        "# Meta-model prediction target: Test predictions from base models\n",
        "stacked_test = np.vstack([lgbm_test_preds, xgb_test_preds, cat_test_preds]).T\n",
        "\n",
        "# Meta-model definition (Ridge)\n",
        "meta_model = Ridge(alpha=1.0) # You can try tuning this alpha, or use RidgeCV\n",
        "\n",
        "# Train meta-model (y is still in log scale)\n",
        "meta_model.fit(stacked_X, y)\n",
        "\n",
        "# Final Stacking prediction (in log scale)\n",
        "stacked_final_preds_log = meta_model.predict(stacked_test)\n",
        "print(\"Stacking 메타 모델 학습 및 예측 완료.\")\n",
        "\n",
        "# ✅ 8. 예측값 역변환 및 클리핑\n",
        "print(\"\\n최종 예측값 역변환 및 클리핑...\")\n",
        "# Reverse log1p transformation\n",
        "final_predictions_original_scale = np.expm1(stacked_final_preds_log)\n",
        "\n",
        "# Clip predictions to be within 0 and 100\n",
        "submission_df['Inhibition'] = np.clip(final_predictions_original_scale, 0, 100)\n",
        "print(\"예측값 처리 완료.\")\n",
        "\n",
        "# ✅ 9. 제출 파일 저장 (Kaggle working directory)\n",
        "output_path = \"/kaggle/working/submission_final_stacking_all_features.csv\"\n",
        "submission_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\n✅ 최종 제출 파일 저장 완료: {output_path}\")\n",
        "print(\"\\n최종 제출 파일 미리보기:\")\n",
        "print(submission_df.head())\n",
        "\n",
        "# (Optional) Final model performance on training data (for reference)\n",
        "print(\"\\n훈련 데이터에 대한 최종 Stacking 모델 성능 평가 (참고용):\")\n",
        "# Stacking model often uses OOF predictions for a more accurate in-sample performance measure\n",
        "final_oof_preds_log = meta_model.predict(stacked_X)\n",
        "final_oof_preds_original_scale = np.expm1(final_oof_preds_log)\n",
        "\n",
        "train_true_original_scale = train_df['Inhibition'] # Original un-transformed target\n",
        "train_mae = mean_squared_error(train_true_original_scale, np.clip(final_oof_preds_original_scale, 0, 100)) # MAE\n",
        "train_rmse = np.sqrt(mean_squared_error(train_true_original_scale, np.clip(final_oof_preds_original_scale, 0, 100))) # RMSE\n",
        "\n",
        "print(f\"훈련 데이터 MAE (Original Scale): {train_mae:.4f}\")\n",
        "print(f\"훈련 데이터 RMSE (Original Scale): {train_rmse:.4f}\")\n",
        "\n",
        "print(f\"\\n--- Kaggle 파이프라인 완료: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())} ---\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T07:31:36.356314Z",
          "iopub.execute_input": "2025-07-01T07:31:36.356673Z",
          "iopub.status.idle": "2025-07-01T07:39:49.63168Z",
          "shell.execute_reply.started": "2025-07-01T07:31:36.356646Z",
          "shell.execute_reply": "2025-07-01T07:39:49.63059Z"
        },
        "id": "Rdd8kuMwED72",
        "outputId": "4fabcde5-bef7-4a15-f740-f31fb53e5a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n기본 모델 학습 시작...\n  LightGBM 학습 시작 (K-Fold CV)...\n    Fold 1/5 완료. RMSE: 1.2366, 소요 시간: 5.80 초\n    Fold 2/5 완료. RMSE: 1.2920, 소요 시간: 5.15 초\n    Fold 3/5 완료. RMSE: 1.2249, 소요 시간: 4.55 초\n    Fold 4/5 완료. RMSE: 1.2298, 소요 시간: 4.55 초\n    Fold 5/5 완료. RMSE: 1.2882, 소요 시간: 4.60 초\n  ✅ LightGBM K-Fold 평균 RMSE (로그 스케일): 1.2543\n  XGBoost 학습 시작 (K-Fold CV)...\n    Fold 1/5 완료. RMSE: 1.2242, 소요 시간: 19.61 초\n    Fold 2/5 완료. RMSE: 1.2528, 소요 시간: 17.82 초\n    Fold 3/5 완료. RMSE: 1.2617, 소요 시간: 19.38 초\n    Fold 4/5 완료. RMSE: 1.2042, 소요 시간: 18.12 초\n    Fold 5/5 완료. RMSE: 1.2684, 소요 시간: 19.63 초\n  ✅ XGBoost K-Fold 평균 RMSE (로그 스케일): 1.2423\n  CatBoost 학습 시작 (K-Fold CV)...\n    Fold 1/5 완료. RMSE: 1.1918, 소요 시간: 74.18 초\n    Fold 2/5 완료. RMSE: 1.2539, 소요 시간: 75.10 초\n    Fold 3/5 완료. RMSE: 1.2154, 소요 시간: 76.10 초\n    Fold 4/5 완료. RMSE: 1.1800, 소요 시간: 74.66 초\n    Fold 5/5 완료. RMSE: 1.2437, 소요 시간: 73.95 초\n  ✅ CatBoost K-Fold 평균 RMSE (로그 스케일): 1.2170\n\n기본 모델 학습 및 예측 완료.\n\nStacking 메타 모델 학습 시작...\nStacking 메타 모델 학습 및 예측 완료.\n\n최종 예측값 역변환 및 클리핑...\n예측값 처리 완료.\n\n✅ 최종 제출 파일 저장 완료: /kaggle/working/submission_final_stacking_all_features.csv\n\n최종 제출 파일 미리보기:\n         ID  Inhibition\n0  TEST_000   17.437155\n1  TEST_001   27.116594\n2  TEST_002   22.339377\n3  TEST_003   26.262970\n4  TEST_004   24.296268\n\n훈련 데이터에 대한 최종 Stacking 모델 성능 평가 (참고용):\n훈련 데이터 MAE (Original Scale): 716.1689\n훈련 데이터 RMSE (Original Scale): 26.7613\n\n--- Kaggle 파이프라인 완료: 2025-07-01 07:39:49 ---\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}