{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1p3yacEnfyNGeB1znN7SjeBRDZtjT-zM3",
      "authorship_tag": "ABX9TyNa5znH2uOYa4xtw0Y9RSf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/dacon_new_drug/blob/main/start(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouk01fRgJCpo",
        "outputId": "977edf87-5de2-4827-cf86-cb811f80810a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/data.zip'\n",
        "extract_path = '/content/project_data'  # 원하는 경로\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "5GSwOCNKKgHv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/project_data/'  # 압축 해제 경로\n",
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')\n",
        "submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "\n",
        "print(train.shape, test.shape, submission.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gor_BqOTLB9m",
        "outputId": "5e922b90-ca9a-4a09-b24d-6981f9fbbc13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1681, 3) (100, 2) (100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RDKit 설치 (Colab에서 가능)\n",
        "!pip uninstall -y rdkit-pypi\n",
        "!pip install rdkit-pypi==2022.9.5 optuna xgboost\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oVRgT8ZLQue",
        "outputId": "0ed09ae6-374f-4067-f424-5b3a16c4a876"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rdkit-pypi 2022.9.5\n",
            "Uninstalling rdkit-pypi-2022.9.5:\n",
            "  Successfully uninstalled rdkit-pypi-2022.9.5\n",
            "Collecting rdkit-pypi==2022.9.5\n",
            "  Using cached rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi==2022.9.5) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi==2022.9.5) (11.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Using cached rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2022.9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ✅ RDKit + XGBoost + Optuna 전체 파이프라인\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors, Lipinski, MACCSkeys, AllChem\n",
        "# import xgboost as xgb\n",
        "# import optuna\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# # ✅ 경로 설정\n",
        "# path = '/content/project_data/'\n",
        "# train = pd.read_csv(path + 'train.csv')\n",
        "# test = pd.read_csv(path + 'test.csv')\n",
        "# submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "\n",
        "# # ✅ 분자 특성 추출 함수\n",
        "# def get_molecule_descriptors(smiles):\n",
        "#     try:\n",
        "#         mol = Chem.MolFromSmiles(smiles)\n",
        "#         if mol is None: return [0] * 2232\n",
        "#         basic = [\n",
        "#             Descriptors.MolWt(mol), Descriptors.MolLogP(mol),\n",
        "#             Descriptors.NumHAcceptors(mol), Descriptors.NumHDonors(mol),\n",
        "#             Descriptors.TPSA(mol), Descriptors.NumRotatableBonds(mol),\n",
        "#             Descriptors.NumAromaticRings(mol), Descriptors.NumHeteroatoms(mol),\n",
        "#             Descriptors.FractionCSP3(mol), Descriptors.NumAliphaticRings(mol),\n",
        "#             Lipinski.NumAromaticHeterocycles(mol), Lipinski.NumSaturatedHeterocycles(mol),\n",
        "#             Lipinski.NumAliphaticHeterocycles(mol), Descriptors.HeavyAtomCount(mol),\n",
        "#             Descriptors.RingCount(mol), Descriptors.NOCount(mol),\n",
        "#             Descriptors.NHOHCount(mol), Descriptors.NumRadicalElectrons(mol)\n",
        "#         ]\n",
        "#         morgan = [int(b) for b in AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048).ToBitString()]\n",
        "#         maccs = [int(b) for b in MACCSkeys.GenMACCSKeys(mol).ToBitString()]\n",
        "#         return basic + morgan + maccs\n",
        "#     except:\n",
        "#         return [0] * 2232\n",
        "\n",
        "# # ✅ 피처 생성\n",
        "# train['features'] = train['Canonical_Smiles'].apply(get_molecule_descriptors)\n",
        "# test['features'] = test['Canonical_Smiles'].apply(get_molecule_descriptors)\n",
        "# X_train = np.array(train['features'].tolist())\n",
        "# y_train = train['Inhibition'].values\n",
        "# X_test = np.array(test['features'].tolist())\n",
        "\n",
        "# # ✅ 정규화\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # ✅ 평가 함수\n",
        "# def normalized_rmse(y_true, y_pred):\n",
        "#     return np.sqrt(mean_squared_error(y_true, y_pred)) / (np.max(y_true) - np.min(y_true))\n",
        "# def pearson_correlation(y_true, y_pred):\n",
        "#     return np.clip(np.corrcoef(y_true, y_pred)[0, 1], 0, 1)\n",
        "# def competition_score(y_true, y_pred):\n",
        "#     return 0.5 * (1 - min(normalized_rmse(y_true, y_pred), 1)) + 0.5 * pearson_correlation(y_true, y_pred)\n",
        "\n",
        "# # ✅ Optuna 튜닝\n",
        "# def objective(trial):\n",
        "#     params = {\n",
        "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1000),\n",
        "#         \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
        "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
        "#         \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 2),\n",
        "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 2),\n",
        "#         \"random_state\": 42\n",
        "#     }\n",
        "#     X_tr, X_val, y_tr, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
        "#     model = xgb.XGBRegressor(**params)\n",
        "#     model.fit(X_tr, y_tr, verbose=False)\n",
        "#     y_val_pred = model.predict(X_val)\n",
        "#     return -competition_score(y_val, y_val_pred)\n",
        "\n",
        "# study = optuna.create_study(direction=\"minimize\")\n",
        "# study.optimize(objective, n_trials=30)\n",
        "\n",
        "# # ✅ 최종 모델 학습 및 예측\n",
        "# final_model = xgb.XGBRegressor(**study.best_params)\n",
        "# final_model.fit(X_train_scaled, y_train)\n",
        "# submission[\"Inhibition\"] = final_model.predict(X_test_scaled)\n",
        "# submission.to_csv(\"submission_optuna_xgb.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "CdBw7KOpLQyt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # ✅ 라이브러리 임포트\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors, Lipinski, MACCSkeys, AllChem\n",
        "# import xgboost as xgb\n",
        "# import optuna\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# path = '/content/project_data/'\n",
        "# train = pd.read_csv(path + 'train.csv')\n",
        "# test = pd.read_csv(path + 'test.csv')\n",
        "# submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "\n",
        "# # ✅ 분자 특성 추출 함수\n",
        "# def get_molecule_descriptors(smiles):\n",
        "#     try:\n",
        "#         mol = Chem.MolFromSmiles(smiles)\n",
        "#         if mol is None: return [0] * 2232\n",
        "#         basic = [\n",
        "#             Descriptors.MolWt(mol), Descriptors.MolLogP(mol),\n",
        "#             Descriptors.NumHAcceptors(mol), Descriptors.NumHDonors(mol),\n",
        "#             Descriptors.TPSA(mol), Descriptors.NumRotatableBonds(mol),\n",
        "#             Descriptors.NumAromaticRings(mol), Descriptors.NumHeteroatoms(mol),\n",
        "#             Descriptors.FractionCSP3(mol), Descriptors.NumAliphaticRings(mol),\n",
        "#             Lipinski.NumAromaticHeterocycles(mol), Lipinski.NumSaturatedHeterocycles(mol),\n",
        "#             Lipinski.NumAliphaticHeterocycles(mol), Descriptors.HeavyAtomCount(mol),\n",
        "#             Descriptors.RingCount(mol), Descriptors.NOCount(mol),\n",
        "#             Descriptors.NHOHCount(mol), Descriptors.NumRadicalElectrons(mol)\n",
        "#         ]\n",
        "#         morgan = [int(b) for b in AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048).ToBitString()]\n",
        "#         maccs = [int(b) for b in MACCSkeys.GenMACCSKeys(mol).ToBitString()]\n",
        "#         return basic + morgan + maccs\n",
        "#     except:\n",
        "#         return [0] * 2232\n",
        "\n",
        "# # ✅ 피처 생성\n",
        "# train['features'] = train['Canonical_Smiles'].apply(get_molecule_descriptors)\n",
        "# test['features'] = test['Canonical_Smiles'].apply(get_molecule_descriptors)\n",
        "# X = np.array(train['features'].tolist())\n",
        "# y = train['Inhibition'].values\n",
        "# X_test = np.array(test['features'].tolist())\n",
        "\n",
        "# # ✅ 정규화\n",
        "# scaler = StandardScaler()\n",
        "# X = scaler.fit_transform(X)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# # ✅ 평가 함수\n",
        "# def normalized_rmse(y_true, y_pred):\n",
        "#     return np.sqrt(mean_squared_error(y_true, y_pred)) / (np.max(y_true) - np.min(y_true))\n",
        "# def pearson_correlation(y_true, y_pred):\n",
        "#     return np.clip(np.corrcoef(y_true, y_pred)[0, 1], 0, 1)\n",
        "# def competition_score(y_true, y_pred):\n",
        "#     return 0.5 * (1 - min(normalized_rmse(y_true, y_pred), 1)) + 0.5 * pearson_correlation(y_true, y_pred)\n",
        "\n",
        "# # ✅ Optuna 튜닝 (1회만, 전체 데이터 기반)\n",
        "# def objective(trial):\n",
        "#     params = {\n",
        "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1000),\n",
        "#         \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
        "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
        "#         \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 2),\n",
        "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 2),\n",
        "#         \"random_state\": 42\n",
        "#     }\n",
        "#     X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#     model = xgb.XGBRegressor(**params)\n",
        "#     model.fit(X_tr, y_tr, verbose=False)\n",
        "#     y_val_pred = model.predict(X_val)\n",
        "#     return -competition_score(y_val, y_val_pred)\n",
        "\n",
        "# study = optuna.create_study(direction=\"minimize\")\n",
        "# study.optimize(objective, n_trials=30)\n",
        "# best_params = study.best_params\n",
        "\n",
        "# # ✅ KFold 앙상블 학습 + 예측\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# test_preds = np.zeros(X_test.shape[0])\n",
        "# scores = []\n",
        "\n",
        "# for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
        "#     print(f\"📂 Fold {fold + 1}\")\n",
        "#     X_tr, X_val = X[tr_idx], X[val_idx]\n",
        "#     y_tr, y_val = y[tr_idx], y[val_idx]\n",
        "\n",
        "#     model = xgb.XGBRegressor(**best_params)\n",
        "#     model.fit(X_tr, y_tr, verbose=False)\n",
        "#     y_val_pred = model.predict(X_val)\n",
        "#     score = competition_score(y_val, y_val_pred)\n",
        "#     print(f\"Fold {fold + 1} Score: {score:.4f}\")\n",
        "#     scores.append(score)\n",
        "\n",
        "#     test_preds += model.predict(X_test) / 5  # 앙상블 평균\n",
        "\n",
        "# # ✅ 후처리: 0~100 클리핑 + float32로 저장\n",
        "# test_preds = np.clip(test_preds, 0, 100)\n",
        "# submission['Inhibition'] = test_preds.astype(np.float32)\n",
        "# submission.to_csv('submission_kfold_optuna.csv', index=False)\n",
        "\n",
        "# print(f\"\\n✅ 평균 Score: {np.mean(scores):.4f}\")\n",
        "# print(\"📁 제출파일 저장 완료: submission_kfold_optuna.csv\")\n"
      ],
      "metadata": {
        "id": "Yadj52TPMuHv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from sklearn.linear_model import Ridge\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from xgboost import XGBRegressor\n",
        "# from lightgbm import LGBMRegressor\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors, Lipinski, MACCSkeys, AllChem\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# # ✅ 데이터 로딩\n",
        "# path = '/content/project_data/'\n",
        "# train = pd.read_csv(path + 'train.csv')\n",
        "# test = pd.read_csv(path + 'test.csv')\n",
        "# submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "\n",
        "\n",
        "# # ✅ Feature 추출 함수\n",
        "# def get_molecule_descriptors(smiles):\n",
        "#     try:\n",
        "#         mol = Chem.MolFromSmiles(smiles)\n",
        "#         if mol is None:\n",
        "#             return [0] * 2232\n",
        "\n",
        "#         basic_descriptors = [\n",
        "#             Descriptors.MolWt(mol),\n",
        "#             Descriptors.MolLogP(mol),\n",
        "#             Descriptors.NumHAcceptors(mol),\n",
        "#             Descriptors.NumHDonors(mol),\n",
        "#             Descriptors.TPSA(mol),\n",
        "#             Descriptors.NumRotatableBonds(mol),\n",
        "#             Descriptors.NumAromaticRings(mol),\n",
        "#             Descriptors.NumHeteroatoms(mol),\n",
        "#             Descriptors.FractionCSP3(mol),\n",
        "#             Descriptors.NumAliphaticRings(mol),\n",
        "#             Lipinski.NumAromaticHeterocycles(mol),\n",
        "#             Lipinski.NumSaturatedHeterocycles(mol),\n",
        "#             Lipinski.NumAliphaticHeterocycles(mol),\n",
        "#             Descriptors.HeavyAtomCount(mol),\n",
        "#             Descriptors.RingCount(mol),\n",
        "#             Descriptors.NOCount(mol),\n",
        "#             Descriptors.NHOHCount(mol),\n",
        "#             Descriptors.NumRadicalElectrons(mol),\n",
        "#         ]\n",
        "\n",
        "#         morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
        "#         morgan_features = [int(bit) for bit in morgan_fp.ToBitString()]\n",
        "#         maccs_fp = MACCSkeys.GenMACCSKeys(mol)\n",
        "#         maccs_features = [int(bit) for bit in maccs_fp.ToBitString()]\n",
        "\n",
        "#         return basic_descriptors + morgan_features + maccs_features\n",
        "#     except:\n",
        "#         return [0] * 2232\n",
        "\n",
        "# # ✅ Feature 생성\n",
        "# train['features'] = train['Canonical_Smiles'].apply(get_molecule_descriptors)\n",
        "# test['features'] = test['Canonical_Smiles'].apply(get_molecule_descriptors)\n",
        "# X = np.array(train['features'].tolist())\n",
        "# y = train['Inhibition'].values\n",
        "# X_test = np.array(test['features'].tolist())\n",
        "\n",
        "# # ✅ 스케일링\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # ✅ Metric\n",
        "# def normalized_rmse(y_true, y_pred):\n",
        "#     return np.sqrt(mean_squared_error(y_true, y_pred)) / (np.max(y_true) - np.min(y_true))\n",
        "\n",
        "# def pearson_correlation(y_true, y_pred):\n",
        "#     return np.clip(np.corrcoef(y_true, y_pred)[0,1], 0, 1)\n",
        "\n",
        "# def competition_score(y_true, y_pred):\n",
        "#     return 0.5 * (1 - normalized_rmse(y_true, y_pred)) + 0.5 * pearson_correlation(y_true, y_pred)\n",
        "\n",
        "# # ✅ 모델 정의\n",
        "# model = LGBMRegressor(\n",
        "#     n_estimators=500, learning_rate=0.05,\n",
        "#     max_depth=6, num_leaves=31,\n",
        "#     subsample=0.8, colsample_bytree=0.8,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# # ✅ 5-Fold 교차검증 + 예측\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# val_scores = []\n",
        "# test_preds = []\n",
        "\n",
        "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
        "#     X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]\n",
        "#     y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "\n",
        "#     model.fit(X_train_fold, y_train_fold)\n",
        "#     val_pred = model.predict(X_val_fold)\n",
        "#     score = competition_score(y_val_fold, val_pred)\n",
        "#     val_scores.append(score)\n",
        "#     print(f\"[Fold {fold+1}] 검증 점수: {score:.4f}\")\n",
        "\n",
        "#     test_pred = model.predict(X_test_scaled)\n",
        "#     test_preds.append(test_pred)\n",
        "\n",
        "# # ✅ 앙상블 (평균)\n",
        "# final_test_pred = np.mean(test_preds, axis=0)\n",
        "\n",
        "# # ✅ 후처리: 0~100 클리핑\n",
        "# final_test_pred = np.clip(final_test_pred, 0, 100)\n",
        "\n",
        "# # ✅ 제출 파일 저장\n",
        "# submission['Inhibition'] = final_test_pred\n",
        "# submission.to_csv(\"submission_kfold_lgbm.csv\", index=False)\n",
        "# print(\"✅ 제출 파일 저장 완료: submission_kfold_lgbm.csv\")\n",
        "# print(f\"평균 검증 점수: {np.mean(val_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "Uw_KQRr0Pdw5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5\n",
        "import os\n",
        "os.kill(os.getpid(), 9)  # 런타임 재시작 (필수)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl-mgMeVuco_",
        "outputId": "dcb78b7e-8568-4ee3-e769-f1c55a00ea9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puyCFz0vtumx",
        "outputId": "b8cf60b7-c38e-4dc3-871c-83fe7d2385bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.2.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ✅ 라이브러리 로딩\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, MACCSkeys, Descriptors, rdMolDescriptors\n",
        "\n",
        "# ✅ 경로 설정 및 데이터 로딩\n",
        "path = '/content/project_data/'\n",
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')\n",
        "submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "\n",
        "# ✅ 1. SMILES 유효성 검사\n",
        "def valid_smiles(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return mol is not None and mol.GetNumAtoms() > 1\n",
        "\n",
        "train = train[train['Canonical_Smiles'].apply(valid_smiles)].reset_index(drop=True)\n",
        "\n",
        "# ✅ 2. 중복 SMILES 평균처리\n",
        "train = train.groupby(\"Canonical_Smiles\").agg({\n",
        "    \"Inhibition\": \"mean\"\n",
        "}).reset_index()\n",
        "\n",
        "# ✅ 3. Canonical SMILES 재정의\n",
        "def canonicalize(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return Chem.MolToSmiles(mol, canonical=True) if mol else smiles\n",
        "\n",
        "train[\"Canonical_Smiles\"] = train[\"Canonical_Smiles\"].apply(canonicalize)\n",
        "test[\"Canonical_Smiles\"] = test[\"Canonical_Smiles\"].apply(canonicalize)\n",
        "\n",
        "# ✅ 4. 확장된 Descriptors 함수 정의\n",
        "def get_expanded_descriptors(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return [0]*5\n",
        "    return [\n",
        "        Descriptors.MolMR(mol),\n",
        "        rdMolDescriptors.CalcExactMolWt(mol),  # MolVol → 분자량으로 대체\n",
        "        Descriptors.BalabanJ(mol),\n",
        "        Descriptors.Chi0(mol),\n",
        "        Descriptors.Kappa1(mol),\n",
        "    ]\n",
        "\n",
        "# ✅ 5. Feature 생성 함수 정의\n",
        "def get_features(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(512)\n",
        "\n",
        "    morgan = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=256)\n",
        "    maccs = MACCSkeys.GenMACCSKeys(mol)\n",
        "    extra = get_expanded_descriptors(smiles)\n",
        "\n",
        "    return np.concatenate([\n",
        "        np.array(morgan),\n",
        "        np.array(maccs),\n",
        "        np.array(extra)\n",
        "    ])\n",
        "\n",
        "# ✅ 전체 feature 변환\n",
        "X = np.array([get_features(s) for s in train['Canonical_Smiles']])\n",
        "X_test = np.array([get_features(s) for s in test['Canonical_Smiles']])\n",
        "y = train['Inhibition'].values\n",
        "\n",
        "# ✅ 표준화\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ 모델 정의\n",
        "base_models = [\n",
        "    ('xgb', XGBRegressor(n_estimators=300, learning_rate=0.1, random_state=42)),\n",
        "    ('lgb', LGBMRegressor(n_estimators=300, learning_rate=0.1, random_state=42)),\n",
        "    ('ridge', Ridge(alpha=1.0))\n",
        "]\n",
        "meta_model = Ridge()\n",
        "\n",
        "stack_model = StackingRegressor(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ KFold 학습 + 추론\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "preds = np.zeros(len(X_test_scaled))\n",
        "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_scaled, y)):\n",
        "    X_train, X_val = X_scaled[tr_idx], X_scaled[val_idx]\n",
        "    y_train, y_val = y[tr_idx], y[val_idx]\n",
        "\n",
        "    stack_model.fit(X_train, y_train)\n",
        "    val_pred = stack_model.predict(X_val)\n",
        "    print(f'Fold {fold+1} MAE:', mean_absolute_error(y_val, val_pred))\n",
        "\n",
        "    preds += stack_model.predict(X_test_scaled) / kf.n_splits\n",
        "\n",
        "# ✅ 결과 저장\n",
        "submission['Inhibition'] = preds\n",
        "submission.to_csv('/content/submission_stack.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVepFr7osHeT",
        "outputId": "d3baf7aa-577b-4517-bfa7-7140e472eb62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 MAE: 20.50232411022973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 MAE: 20.056287300003262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 MAE: 19.282389806215498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 MAE: 21.050464016475864\n",
            "Fold 5 MAE: 21.122982024070637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, MACCSkeys, AllChem\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# ✅ 데이터 경로\n",
        "path = '/content/project_data/'\n",
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')\n",
        "submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "\n",
        "# ✅ 유효한 SMILES 필터링\n",
        "def valid_smiles(smi):\n",
        "    mol = Chem.MolFromSmiles(smi)\n",
        "    return mol is not None and mol.GetNumAtoms() > 1\n",
        "\n",
        "train = train[train['Canonical_Smiles'].apply(valid_smiles)].reset_index(drop=True)\n",
        "\n",
        "# ✅ Canonicalization\n",
        "def canonicalize(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return Chem.MolToSmiles(mol, canonical=True) if mol else smiles\n",
        "\n",
        "train['Canonical_Smiles'] = train['Canonical_Smiles'].apply(canonicalize)\n",
        "test['Canonical_Smiles'] = test['Canonical_Smiles'].apply(canonicalize)\n",
        "\n",
        "# ✅ Feature 생성\n",
        "def get_features(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(512 + 167 + 5)\n",
        "\n",
        "    morgan = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512)\n",
        "    morgan_np = np.array(morgan)\n",
        "\n",
        "    maccs = MACCSkeys.GenMACCSKeys(mol)\n",
        "    maccs_np = np.array(maccs)[1:]\n",
        "\n",
        "    others = np.array([\n",
        "        Descriptors.MolMR(mol),\n",
        "        Descriptors.BalabanJ(mol),\n",
        "        Descriptors.Chi0(mol),\n",
        "        Descriptors.Chi1(mol),\n",
        "        Descriptors.Kappa1(mol)\n",
        "    ])\n",
        "\n",
        "    return np.concatenate([morgan_np, maccs_np, others])\n",
        "\n",
        "X = np.array([get_features(smi) for smi in train['Canonical_Smiles']])\n",
        "X_test = np.array([get_features(smi) for smi in test['Canonical_Smiles']])\n",
        "y = train['Inhibition'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ✅ KFold 설정\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "def run_stacking(meta_model, file_name):\n",
        "    base_models = [\n",
        "        ('xgb', XGBRegressor(n_estimators=300, random_state=42)),\n",
        "        ('lgbm', LGBMRegressor(n_estimators=300, random_state=42)),\n",
        "        ('cat', CatBoostRegressor(n_estimators=300, verbose=0, random_state=42))\n",
        "    ]\n",
        "\n",
        "    stack = StackingRegressor(\n",
        "        estimators=base_models,\n",
        "        final_estimator=meta_model,\n",
        "        passthrough=True,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    preds = np.zeros(len(X_test))\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_tr, X_val = X[train_idx], X[val_idx]\n",
        "        y_tr, y_val = y[train_idx], y[val_idx]\n",
        "        stack.fit(X_tr, y_tr)\n",
        "        preds += stack.predict(X_test) / kf.n_splits\n",
        "\n",
        "    submission['Inhibition'] = preds\n",
        "    submission.to_csv(file_name, index=False)\n",
        "\n",
        "# ✅ 전략 2: Meta → LinearRegression\n",
        "run_stacking(LinearRegression(), 'submission_stack_linear.csv')\n",
        "\n",
        "# ✅ 전략 3: Meta → LGBM (CatBoost 포함)\n",
        "run_stacking(LGBMRegressor(n_estimators=100, random_state=42), 'submission_stack_lgbm.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dUA8GTOwuQm",
        "outputId": "48b2132e-2962-4d10-d626-99282ae68983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016211 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3975\n",
            "[LightGBM] [Info] Number of data points in the train set: 1344, number of used features: 653\n",
            "[LightGBM] [Info] Start training from score 33.391242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015918 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3969\n",
            "[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 651\n",
            "[LightGBM] [Info] Start training from score 33.637152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3972\n",
            "[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 652\n",
            "[LightGBM] [Info] Start training from score 33.054065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}