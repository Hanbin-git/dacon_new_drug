{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12288614,
          "sourceType": "datasetVersion",
          "datasetId": 7744692
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook5a12e8f9ad",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/dacon_new_drug/blob/main/20250626(4)\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "FTKKjqK2VAiq"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "biniroun_datafile1_path = kagglehub.dataset_download('biniroun/datafile1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "P087UeLFVAiv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret[full] rdkit-pypi --quiet\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T06:58:20.914823Z",
          "iopub.execute_input": "2025-06-26T06:58:20.91509Z",
          "iopub.status.idle": "2025-06-26T07:00:11.557963Z",
          "shell.execute_reply.started": "2025-06-26T06:58:20.915057Z",
          "shell.execute_reply": "2025-06-26T07:00:11.557151Z"
        },
        "id": "0Xpwh9e_VAiw",
        "outputId": "1a06a74e-3842-4a14-efa0-53082b128e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.1/355.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.8/279.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.1/486.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.5/236.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.2/573.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.2/169.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.9/778.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for fugue-sql-antlr (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for dash-cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\nomegaconf 2.3.0 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.11.1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\nmizani 0.13.2 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nplotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ✅ 데이터 경로\n",
        "data_path = \"/kaggle/input/datafile1\"\n",
        "\n",
        "# ✅ CSV 파일 로드\n",
        "train = pd.read_csv(f\"{data_path}/train.csv\")\n",
        "test = pd.read_csv(f\"{data_path}/test.csv\")\n",
        "submission = pd.read_csv(f\"{data_path}/sample_submission.csv\")\n",
        "\n",
        "# ✅ 데이터 확인\n",
        "print(\"✅ train shape:\", train.shape)\n",
        "print(\"✅ test shape:\", test.shape)\n",
        "print(\"✅ submission shape:\", submission.shape)\n",
        "train.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:01:04.939974Z",
          "iopub.execute_input": "2025-06-26T07:01:04.94062Z",
          "iopub.status.idle": "2025-06-26T07:01:04.962667Z",
          "shell.execute_reply.started": "2025-06-26T07:01:04.940593Z",
          "shell.execute_reply": "2025-06-26T07:01:04.961964Z"
        },
        "id": "hJa8xRHyVAiy",
        "outputId": "7f0e69a4-c052-453c-cf82-fec892140c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ train shape: (1681, 3)\n✅ test shape: (100, 2)\n✅ submission shape: (100, 2)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           ID                                   Canonical_Smiles  Inhibition\n0  TRAIN_0000                        Cl.OC1(Cc2cccc(Br)c2)CCNCC1       12.50\n1  TRAIN_0001                              Brc1ccc2OCCc3ccnc1c23        4.45\n2  TRAIN_0002         CC1(CO)CC(=NO1)c2cc(c(F)cc2Cl)[N+](=O)[O-]        4.92\n3  TRAIN_0003  Fc1ccc2nc(Nc3cccc(COc4cccc(c4)C(=O)N5CCOCC5)c3...       71.50\n4  TRAIN_0004       CC(C)CC(=O)C1=C(Nc2c(Cl)ccc(Cl)c2C1=O)S(=O)C       18.30",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Canonical_Smiles</th>\n      <th>Inhibition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_0000</td>\n      <td>Cl.OC1(Cc2cccc(Br)c2)CCNCC1</td>\n      <td>12.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_0001</td>\n      <td>Brc1ccc2OCCc3ccnc1c23</td>\n      <td>4.45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_0002</td>\n      <td>CC1(CO)CC(=NO1)c2cc(c(F)cc2Cl)[N+](=O)[O-]</td>\n      <td>4.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_0003</td>\n      <td>Fc1ccc2nc(Nc3cccc(COc4cccc(c4)C(=O)N5CCOCC5)c3...</td>\n      <td>71.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_0004</td>\n      <td>CC(C)CC(=O)C1=C(Nc2c(Cl)ccc(Cl)c2C1=O)S(=O)C</td>\n      <td>18.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # ✅ 1. 라이브러리\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import AllChem\n",
        "# from lightgbm import LGBMRegressor\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import mean_absolute_error\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # ✅ 2. 데이터 로드\n",
        "# data_path = \"/kaggle/input/datafile1\"\n",
        "# train = pd.read_csv(f\"{data_path}/train.csv\")\n",
        "# test = pd.read_csv(f\"{data_path}/test.csv\")\n",
        "# submission = pd.read_csv(f\"{data_path}/sample_submission.csv\")\n",
        "\n",
        "# # ✅ 3. Fingerprint 변환 함수\n",
        "# def smiles_to_morgan(smiles_list, radius=2, n_bits=2048):\n",
        "#     fps = []\n",
        "#     for smi in tqdm(smiles_list):\n",
        "#         mol = Chem.MolFromSmiles(smi)\n",
        "#         if mol is not None:\n",
        "#             fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
        "#             arr = np.zeros((1,), dtype=int)\n",
        "#             AllChem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "#             fps.append(arr)\n",
        "#         else:\n",
        "#             fps.append(np.zeros((n_bits,), dtype=int))  # 실패한 경우 0벡터\n",
        "#     return np.array(fps)\n",
        "\n",
        "# # ✅ 4. Feature Engineering\n",
        "# X = smiles_to_morgan(train[\"Canonical_Smiles\"])\n",
        "# X_test = smiles_to_morgan(test[\"Canonical_Smiles\"])\n",
        "# y = train[\"Inhibition\"]\n",
        "\n",
        "# # ✅ 5. 모델 훈련 (LightGBM + 5-Fold CV)\n",
        "# preds = np.zeros(X_test.shape[0])\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# mae_scores = []\n",
        "\n",
        "# for train_idx, val_idx in kf.split(X):\n",
        "#     X_tr, X_val = X[train_idx], X[val_idx]\n",
        "#     y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "#     model = LGBMRegressor(random_state=42)\n",
        "#     model.fit(X_tr, y_tr)\n",
        "\n",
        "#     val_pred = model.predict(X_val)\n",
        "#     mae = mean_absolute_error(y_val, val_pred)\n",
        "#     mae_scores.append(mae)\n",
        "\n",
        "#     preds += model.predict(X_test) / kf.n_splits\n",
        "\n",
        "# print(\"✅ 평균 MAE:\", np.mean(mae_scores))\n",
        "\n",
        "# # ✅ 6. 제출 파일 생성\n",
        "# submission[\"Inhibition\"] = preds\n",
        "# submission.to_csv(\"submission.csv\", index=False)\n",
        "# print(\"🎉 submission.csv 저장 완료!\")\n",
        "# #"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:01:07.278699Z",
          "iopub.execute_input": "2025-06-26T07:01:07.279459Z",
          "iopub.status.idle": "2025-06-26T07:01:14.180076Z",
          "shell.execute_reply.started": "2025-06-26T07:01:07.279422Z",
          "shell.execute_reply": "2025-06-26T07:01:14.179238Z"
        },
        "id": "A86AOnJMVAiz",
        "outputId": "808781dd-655b-47e3-fb7c-ebe09321977d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 1681/1681 [00:00<00:00, 3460.94it/s]\n100%|██████████| 100/100 [00:00<00:00, 3520.25it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007738 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1208\n[LightGBM] [Info] Number of data points in the train set: 1344, number of used features: 604\n[LightGBM] [Info] Start training from score 33.391242\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005176 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1218\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 609\n[LightGBM] [Info] Start training from score 33.637152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005197 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1200\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 600\n[LightGBM] [Info] Start training from score 33.054065\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004826 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1194\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 597\n[LightGBM] [Info] Start training from score 33.229167\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004558 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1186\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 593\n[LightGBM] [Info] Start training from score 32.797655\n✅ 평균 MAE: 20.807345395483274\n🎉 submission.csv 저장 완료!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import warnings\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from pycaret.regression import *\n",
        "from rdkit import rdBase\n",
        "rdBase.DisableLog('rdApp.error')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ✅ 실제 Kaggle 경로 사용\n",
        "train_path = \"/kaggle/input/datafile1/train.csv\"\n",
        "test_path = \"/kaggle/input/datafile1/test.csv\"\n",
        "submission_path = \"/kaggle/input/datafile1/sample_submission.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "submission_df = pd.read_csv(submission_path)\n",
        "\n",
        "print(\"✅ train_df:\", train_df.shape)\n",
        "print(\"✅ test_df:\", test_df.shape)\n",
        "print(\"✅ submission_df:\", submission_df.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:07:10.687626Z",
          "iopub.execute_input": "2025-06-26T07:07:10.688232Z",
          "iopub.status.idle": "2025-06-26T07:07:32.717788Z",
          "shell.execute_reply.started": "2025-06-26T07:07:10.688205Z",
          "shell.execute_reply": "2025-06-26T07:07:32.717099Z"
        },
        "id": "_1kcPZhVVAi0",
        "outputId": "dd0dd7ef-b021-4fdd-ec70-6ceca670f7ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ train_df: (1681, 3)\n✅ test_df: (100, 2)\n✅ submission_df: (100, 2)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_morgan_fingerprint(smiles_string, n_bits=2048, radius=2):\n",
        "    \"\"\"SMILES → Morgan Fingerprint (numpy array)\"\"\"\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles_string)\n",
        "        if mol is not None:\n",
        "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
        "            return np.array(fp)\n",
        "        else:\n",
        "            return np.zeros(n_bits, dtype=int)\n",
        "    except:\n",
        "        return np.zeros(n_bits, dtype=int)\n",
        "\n",
        "# Fingerprint 추출\n",
        "train_fps = train_df['Canonical_Smiles'].apply(get_morgan_fingerprint)\n",
        "test_fps = test_df['Canonical_Smiles'].apply(get_morgan_fingerprint)\n",
        "\n",
        "# DataFrame 변환\n",
        "fp_columns = [f'FP_{i}' for i in range(2048)]\n",
        "train_fp_df = pd.DataFrame(np.vstack(train_fps.values), columns=fp_columns)\n",
        "test_fp_df = pd.DataFrame(np.vstack(test_fps.values), columns=fp_columns)\n",
        "\n",
        "# PyCaret용 최종 학습 데이터\n",
        "pycaret_train_df = pd.concat([train_fp_df, train_df['Inhibition']], axis=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:07:36.686211Z",
          "iopub.execute_input": "2025-06-26T07:07:36.686568Z",
          "iopub.status.idle": "2025-06-26T07:07:38.296734Z",
          "shell.execute_reply.started": "2025-06-26T07:07:36.686544Z",
          "shell.execute_reply": "2025-06-26T07:07:38.296168Z"
        },
        "id": "ZkznhcLvVAi1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ PyCaret 환경 설정\n",
        "s = setup(data=pycaret_train_df,\n",
        "          target='Inhibition',\n",
        "          session_id=42,\n",
        "          fold=5,\n",
        "          normalize=True,\n",
        "          normalize_method='minmax',\n",
        "          verbose=False)\n",
        "\n",
        "# ✅ 여러 모델 비교 및 최적 모델 선택\n",
        "best_model = compare_models(sort='RMSE', n_select=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:07:44.661011Z",
          "iopub.execute_input": "2025-06-26T07:07:44.661299Z",
          "iopub.status.idle": "2025-06-26T07:12:47.663247Z",
          "shell.execute_reply.started": "2025-06-26T07:07:44.661271Z",
          "shell.execute_reply": "2025-06-26T07:12:47.662422Z"
        },
        "id": "h1cPT4aOVAi2",
        "outputId": "77df93d2-8c06-4f15-af30-173930913679"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<pandas.io.formats.style.Styler at 0x7a45e0b58110>",
            "text/html": "<style type=\"text/css\">\n#T_fc5dd th {\n  text-align: left;\n}\n#T_fc5dd_row0_col0, #T_fc5dd_row0_col5, #T_fc5dd_row0_col6, #T_fc5dd_row1_col0, #T_fc5dd_row1_col1, #T_fc5dd_row1_col2, #T_fc5dd_row1_col3, #T_fc5dd_row1_col4, #T_fc5dd_row1_col6, #T_fc5dd_row2_col0, #T_fc5dd_row2_col1, #T_fc5dd_row2_col2, #T_fc5dd_row2_col3, #T_fc5dd_row2_col4, #T_fc5dd_row2_col5, #T_fc5dd_row2_col6, #T_fc5dd_row3_col0, #T_fc5dd_row3_col1, #T_fc5dd_row3_col2, #T_fc5dd_row3_col3, #T_fc5dd_row3_col4, #T_fc5dd_row3_col5, #T_fc5dd_row3_col6, #T_fc5dd_row4_col0, #T_fc5dd_row4_col1, #T_fc5dd_row4_col2, #T_fc5dd_row4_col3, #T_fc5dd_row4_col4, #T_fc5dd_row4_col5, #T_fc5dd_row4_col6, #T_fc5dd_row5_col0, #T_fc5dd_row5_col1, #T_fc5dd_row5_col2, #T_fc5dd_row5_col3, #T_fc5dd_row5_col4, #T_fc5dd_row5_col5, #T_fc5dd_row5_col6, #T_fc5dd_row6_col0, #T_fc5dd_row6_col1, #T_fc5dd_row6_col2, #T_fc5dd_row6_col3, #T_fc5dd_row6_col4, #T_fc5dd_row6_col5, #T_fc5dd_row6_col6, #T_fc5dd_row7_col0, #T_fc5dd_row7_col1, #T_fc5dd_row7_col2, #T_fc5dd_row7_col3, #T_fc5dd_row7_col4, #T_fc5dd_row7_col5, #T_fc5dd_row7_col6, #T_fc5dd_row8_col0, #T_fc5dd_row8_col1, #T_fc5dd_row8_col2, #T_fc5dd_row8_col3, #T_fc5dd_row8_col4, #T_fc5dd_row8_col5, #T_fc5dd_row8_col6, #T_fc5dd_row9_col0, #T_fc5dd_row9_col1, #T_fc5dd_row9_col2, #T_fc5dd_row9_col3, #T_fc5dd_row9_col4, #T_fc5dd_row9_col5, #T_fc5dd_row9_col6, #T_fc5dd_row10_col0, #T_fc5dd_row10_col1, #T_fc5dd_row10_col2, #T_fc5dd_row10_col3, #T_fc5dd_row10_col4, #T_fc5dd_row10_col5, #T_fc5dd_row10_col6, #T_fc5dd_row11_col0, #T_fc5dd_row11_col1, #T_fc5dd_row11_col2, #T_fc5dd_row11_col3, #T_fc5dd_row11_col4, #T_fc5dd_row11_col5, #T_fc5dd_row12_col0, #T_fc5dd_row12_col1, #T_fc5dd_row12_col2, #T_fc5dd_row12_col3, #T_fc5dd_row12_col4, #T_fc5dd_row12_col5, #T_fc5dd_row12_col6, #T_fc5dd_row13_col0, #T_fc5dd_row13_col1, #T_fc5dd_row13_col2, #T_fc5dd_row13_col3, #T_fc5dd_row13_col4, #T_fc5dd_row13_col5, #T_fc5dd_row13_col6, #T_fc5dd_row14_col0, #T_fc5dd_row14_col1, #T_fc5dd_row14_col2, #T_fc5dd_row14_col3, #T_fc5dd_row14_col4, #T_fc5dd_row14_col5, #T_fc5dd_row14_col6, #T_fc5dd_row15_col0, #T_fc5dd_row15_col1, #T_fc5dd_row15_col2, #T_fc5dd_row15_col3, #T_fc5dd_row15_col4, #T_fc5dd_row15_col5, #T_fc5dd_row15_col6, #T_fc5dd_row16_col0, #T_fc5dd_row16_col1, #T_fc5dd_row16_col2, #T_fc5dd_row16_col3, #T_fc5dd_row16_col4, #T_fc5dd_row16_col5, #T_fc5dd_row16_col6, #T_fc5dd_row17_col0, #T_fc5dd_row17_col1, #T_fc5dd_row17_col2, #T_fc5dd_row17_col3, #T_fc5dd_row17_col4, #T_fc5dd_row17_col5, #T_fc5dd_row17_col6, #T_fc5dd_row18_col0, #T_fc5dd_row18_col1, #T_fc5dd_row18_col2, #T_fc5dd_row18_col3, #T_fc5dd_row18_col4, #T_fc5dd_row18_col5, #T_fc5dd_row18_col6, #T_fc5dd_row19_col0, #T_fc5dd_row19_col1, #T_fc5dd_row19_col2, #T_fc5dd_row19_col3, #T_fc5dd_row19_col4, #T_fc5dd_row19_col5, #T_fc5dd_row19_col6 {\n  text-align: left;\n}\n#T_fc5dd_row0_col1, #T_fc5dd_row0_col2, #T_fc5dd_row0_col3, #T_fc5dd_row0_col4, #T_fc5dd_row1_col5, #T_fc5dd_row11_col6 {\n  text-align: left;\n  background-color: yellow;\n}\n#T_fc5dd_row0_col7, #T_fc5dd_row1_col7, #T_fc5dd_row2_col7, #T_fc5dd_row3_col7, #T_fc5dd_row4_col7, #T_fc5dd_row5_col7, #T_fc5dd_row6_col7, #T_fc5dd_row7_col7, #T_fc5dd_row8_col7, #T_fc5dd_row10_col7, #T_fc5dd_row11_col7, #T_fc5dd_row12_col7, #T_fc5dd_row13_col7, #T_fc5dd_row14_col7, #T_fc5dd_row15_col7, #T_fc5dd_row16_col7, #T_fc5dd_row17_col7, #T_fc5dd_row18_col7, #T_fc5dd_row19_col7 {\n  text-align: left;\n  background-color: lightgrey;\n}\n#T_fc5dd_row9_col7 {\n  text-align: left;\n  background-color: yellow;\n  background-color: lightgrey;\n}\n</style>\n<table id=\"T_fc5dd\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_fc5dd_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n      <th id=\"T_fc5dd_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n      <th id=\"T_fc5dd_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n      <th id=\"T_fc5dd_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n      <th id=\"T_fc5dd_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n      <th id=\"T_fc5dd_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n      <th id=\"T_fc5dd_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n      <th id=\"T_fc5dd_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_fc5dd_level0_row0\" class=\"row_heading level0 row0\" >br</th>\n      <td id=\"T_fc5dd_row0_col0\" class=\"data row0 col0\" >Bayesian Ridge</td>\n      <td id=\"T_fc5dd_row0_col1\" class=\"data row0 col1\" >21.0313</td>\n      <td id=\"T_fc5dd_row0_col2\" class=\"data row0 col2\" >643.1184</td>\n      <td id=\"T_fc5dd_row0_col3\" class=\"data row0 col3\" >25.3313</td>\n      <td id=\"T_fc5dd_row0_col4\" class=\"data row0 col4\" >0.0841</td>\n      <td id=\"T_fc5dd_row0_col5\" class=\"data row0 col5\" >1.3562</td>\n      <td id=\"T_fc5dd_row0_col6\" class=\"data row0 col6\" >5.5619</td>\n      <td id=\"T_fc5dd_row0_col7\" class=\"data row0 col7\" >1.1000</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n      <td id=\"T_fc5dd_row1_col0\" class=\"data row1 col0\" >Random Forest Regressor</td>\n      <td id=\"T_fc5dd_row1_col1\" class=\"data row1 col1\" >21.0550</td>\n      <td id=\"T_fc5dd_row1_col2\" class=\"data row1 col2\" >661.6154</td>\n      <td id=\"T_fc5dd_row1_col3\" class=\"data row1 col3\" >25.6895</td>\n      <td id=\"T_fc5dd_row1_col4\" class=\"data row1 col4\" >0.0580</td>\n      <td id=\"T_fc5dd_row1_col5\" class=\"data row1 col5\" >1.3258</td>\n      <td id=\"T_fc5dd_row1_col6\" class=\"data row1 col6\" >5.1628</td>\n      <td id=\"T_fc5dd_row1_col7\" class=\"data row1 col7\" >6.1400</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row2\" class=\"row_heading level0 row2\" >llar</th>\n      <td id=\"T_fc5dd_row2_col0\" class=\"data row2 col0\" >Lasso Least Angle Regression</td>\n      <td id=\"T_fc5dd_row2_col1\" class=\"data row2 col1\" >21.8003</td>\n      <td id=\"T_fc5dd_row2_col2\" class=\"data row2 col2\" >678.5771</td>\n      <td id=\"T_fc5dd_row2_col3\" class=\"data row2 col3\" >26.0170</td>\n      <td id=\"T_fc5dd_row2_col4\" class=\"data row2 col4\" >0.0342</td>\n      <td id=\"T_fc5dd_row2_col5\" class=\"data row2 col5\" >1.3839</td>\n      <td id=\"T_fc5dd_row2_col6\" class=\"data row2 col6\" >5.8185</td>\n      <td id=\"T_fc5dd_row2_col7\" class=\"data row2 col7\" >0.2780</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row3\" class=\"row_heading level0 row3\" >lasso</th>\n      <td id=\"T_fc5dd_row3_col0\" class=\"data row3 col0\" >Lasso Regression</td>\n      <td id=\"T_fc5dd_row3_col1\" class=\"data row3 col1\" >21.8003</td>\n      <td id=\"T_fc5dd_row3_col2\" class=\"data row3 col2\" >678.5772</td>\n      <td id=\"T_fc5dd_row3_col3\" class=\"data row3 col3\" >26.0170</td>\n      <td id=\"T_fc5dd_row3_col4\" class=\"data row3 col4\" >0.0342</td>\n      <td id=\"T_fc5dd_row3_col5\" class=\"data row3 col5\" >1.3839</td>\n      <td id=\"T_fc5dd_row3_col6\" class=\"data row3 col6\" >5.8186</td>\n      <td id=\"T_fc5dd_row3_col7\" class=\"data row3 col7\" >0.2740</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row4\" class=\"row_heading level0 row4\" >en</th>\n      <td id=\"T_fc5dd_row4_col0\" class=\"data row4 col0\" >Elastic Net</td>\n      <td id=\"T_fc5dd_row4_col1\" class=\"data row4 col1\" >21.8877</td>\n      <td id=\"T_fc5dd_row4_col2\" class=\"data row4 col2\" >682.6070</td>\n      <td id=\"T_fc5dd_row4_col3\" class=\"data row4 col3\" >26.0949</td>\n      <td id=\"T_fc5dd_row4_col4\" class=\"data row4 col4\" >0.0284</td>\n      <td id=\"T_fc5dd_row4_col5\" class=\"data row4 col5\" >1.3875</td>\n      <td id=\"T_fc5dd_row4_col6\" class=\"data row4 col6\" >5.8932</td>\n      <td id=\"T_fc5dd_row4_col7\" class=\"data row4 col7\" >0.2880</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row5\" class=\"row_heading level0 row5\" >gbr</th>\n      <td id=\"T_fc5dd_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Regressor</td>\n      <td id=\"T_fc5dd_row5_col1\" class=\"data row5 col1\" >21.5632</td>\n      <td id=\"T_fc5dd_row5_col2\" class=\"data row5 col2\" >684.5222</td>\n      <td id=\"T_fc5dd_row5_col3\" class=\"data row5 col3\" >26.1268</td>\n      <td id=\"T_fc5dd_row5_col4\" class=\"data row5 col4\" >0.0261</td>\n      <td id=\"T_fc5dd_row5_col5\" class=\"data row5 col5\" >1.3760</td>\n      <td id=\"T_fc5dd_row5_col6\" class=\"data row5 col6\" >5.7961</td>\n      <td id=\"T_fc5dd_row5_col7\" class=\"data row5 col7\" >1.3320</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row6\" class=\"row_heading level0 row6\" >catboost</th>\n      <td id=\"T_fc5dd_row6_col0\" class=\"data row6 col0\" >CatBoost Regressor</td>\n      <td id=\"T_fc5dd_row6_col1\" class=\"data row6 col1\" >21.5711</td>\n      <td id=\"T_fc5dd_row6_col2\" class=\"data row6 col2\" >694.4035</td>\n      <td id=\"T_fc5dd_row6_col3\" class=\"data row6 col3\" >26.3328</td>\n      <td id=\"T_fc5dd_row6_col4\" class=\"data row6 col4\" >0.0081</td>\n      <td id=\"T_fc5dd_row6_col5\" class=\"data row6 col5\" >1.3714</td>\n      <td id=\"T_fc5dd_row6_col6\" class=\"data row6 col6\" >5.6998</td>\n      <td id=\"T_fc5dd_row6_col7\" class=\"data row6 col7\" >6.1980</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row7\" class=\"row_heading level0 row7\" >lightgbm</th>\n      <td id=\"T_fc5dd_row7_col0\" class=\"data row7 col0\" >Light Gradient Boosting Machine</td>\n      <td id=\"T_fc5dd_row7_col1\" class=\"data row7 col1\" >21.5410</td>\n      <td id=\"T_fc5dd_row7_col2\" class=\"data row7 col2\" >695.4474</td>\n      <td id=\"T_fc5dd_row7_col3\" class=\"data row7 col3\" >26.3534</td>\n      <td id=\"T_fc5dd_row7_col4\" class=\"data row7 col4\" >0.0074</td>\n      <td id=\"T_fc5dd_row7_col5\" class=\"data row7 col5\" >1.3694</td>\n      <td id=\"T_fc5dd_row7_col6\" class=\"data row7 col6\" >5.2157</td>\n      <td id=\"T_fc5dd_row7_col7\" class=\"data row7 col7\" >18.7060</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row8\" class=\"row_heading level0 row8\" >ada</th>\n      <td id=\"T_fc5dd_row8_col0\" class=\"data row8 col0\" >AdaBoost Regressor</td>\n      <td id=\"T_fc5dd_row8_col1\" class=\"data row8 col1\" >22.3830</td>\n      <td id=\"T_fc5dd_row8_col2\" class=\"data row8 col2\" >695.5039</td>\n      <td id=\"T_fc5dd_row8_col3\" class=\"data row8 col3\" >26.3583</td>\n      <td id=\"T_fc5dd_row8_col4\" class=\"data row8 col4\" >0.0069</td>\n      <td id=\"T_fc5dd_row8_col5\" class=\"data row8 col5\" >1.4323</td>\n      <td id=\"T_fc5dd_row8_col6\" class=\"data row8 col6\" >6.5755</td>\n      <td id=\"T_fc5dd_row8_col7\" class=\"data row8 col7\" >1.1720</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row9\" class=\"row_heading level0 row9\" >dummy</th>\n      <td id=\"T_fc5dd_row9_col0\" class=\"data row9 col0\" >Dummy Regressor</td>\n      <td id=\"T_fc5dd_row9_col1\" class=\"data row9 col1\" >22.2970</td>\n      <td id=\"T_fc5dd_row9_col2\" class=\"data row9 col2\" >708.6996</td>\n      <td id=\"T_fc5dd_row9_col3\" class=\"data row9 col3\" >26.5932</td>\n      <td id=\"T_fc5dd_row9_col4\" class=\"data row9 col4\" >-0.0094</td>\n      <td id=\"T_fc5dd_row9_col5\" class=\"data row9 col5\" >1.4002</td>\n      <td id=\"T_fc5dd_row9_col6\" class=\"data row9 col6\" >6.0433</td>\n      <td id=\"T_fc5dd_row9_col7\" class=\"data row9 col7\" >0.2660</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row10\" class=\"row_heading level0 row10\" >xgboost</th>\n      <td id=\"T_fc5dd_row10_col0\" class=\"data row10 col0\" >Extreme Gradient Boosting</td>\n      <td id=\"T_fc5dd_row10_col1\" class=\"data row10 col1\" >22.4551</td>\n      <td id=\"T_fc5dd_row10_col2\" class=\"data row10 col2\" >758.8901</td>\n      <td id=\"T_fc5dd_row10_col3\" class=\"data row10 col3\" >27.5265</td>\n      <td id=\"T_fc5dd_row10_col4\" class=\"data row10 col4\" >-0.0839</td>\n      <td id=\"T_fc5dd_row10_col5\" class=\"data row10 col5\" >1.3886</td>\n      <td id=\"T_fc5dd_row10_col6\" class=\"data row10 col6\" >5.6420</td>\n      <td id=\"T_fc5dd_row10_col7\" class=\"data row10 col7\" >0.8980</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row11\" class=\"row_heading level0 row11\" >knn</th>\n      <td id=\"T_fc5dd_row11_col0\" class=\"data row11 col0\" >K Neighbors Regressor</td>\n      <td id=\"T_fc5dd_row11_col1\" class=\"data row11 col1\" >23.1917</td>\n      <td id=\"T_fc5dd_row11_col2\" class=\"data row11 col2\" >827.1634</td>\n      <td id=\"T_fc5dd_row11_col3\" class=\"data row11 col3\" >28.7244</td>\n      <td id=\"T_fc5dd_row11_col4\" class=\"data row11 col4\" >-0.1781</td>\n      <td id=\"T_fc5dd_row11_col5\" class=\"data row11 col5\" >1.3847</td>\n      <td id=\"T_fc5dd_row11_col6\" class=\"data row11 col6\" >5.0824</td>\n      <td id=\"T_fc5dd_row11_col7\" class=\"data row11 col7\" >0.3260</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row12\" class=\"row_heading level0 row12\" >ridge</th>\n      <td id=\"T_fc5dd_row12_col0\" class=\"data row12 col0\" >Ridge Regression</td>\n      <td id=\"T_fc5dd_row12_col1\" class=\"data row12 col1\" >25.0705</td>\n      <td id=\"T_fc5dd_row12_col2\" class=\"data row12 col2\" >967.8800</td>\n      <td id=\"T_fc5dd_row12_col3\" class=\"data row12 col3\" >31.1009</td>\n      <td id=\"T_fc5dd_row12_col4\" class=\"data row12 col4\" >-0.3876</td>\n      <td id=\"T_fc5dd_row12_col5\" class=\"data row12 col5\" >1.4688</td>\n      <td id=\"T_fc5dd_row12_col6\" class=\"data row12 col6\" >5.4593</td>\n      <td id=\"T_fc5dd_row12_col7\" class=\"data row12 col7\" >0.2680</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row13\" class=\"row_heading level0 row13\" >huber</th>\n      <td id=\"T_fc5dd_row13_col0\" class=\"data row13 col0\" >Huber Regressor</td>\n      <td id=\"T_fc5dd_row13_col1\" class=\"data row13 col1\" >25.7914</td>\n      <td id=\"T_fc5dd_row13_col2\" class=\"data row13 col2\" >1035.3330</td>\n      <td id=\"T_fc5dd_row13_col3\" class=\"data row13 col3\" >32.1667</td>\n      <td id=\"T_fc5dd_row13_col4\" class=\"data row13 col4\" >-0.4847</td>\n      <td id=\"T_fc5dd_row13_col5\" class=\"data row13 col5\" >1.4677</td>\n      <td id=\"T_fc5dd_row13_col6\" class=\"data row13 col6\" >5.5262</td>\n      <td id=\"T_fc5dd_row13_col7\" class=\"data row13 col7\" >1.0480</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row14\" class=\"row_heading level0 row14\" >omp</th>\n      <td id=\"T_fc5dd_row14_col0\" class=\"data row14 col0\" >Orthogonal Matching Pursuit</td>\n      <td id=\"T_fc5dd_row14_col1\" class=\"data row14 col1\" >25.6402</td>\n      <td id=\"T_fc5dd_row14_col2\" class=\"data row14 col2\" >1036.1041</td>\n      <td id=\"T_fc5dd_row14_col3\" class=\"data row14 col3\" >32.1707</td>\n      <td id=\"T_fc5dd_row14_col4\" class=\"data row14 col4\" >-0.4803</td>\n      <td id=\"T_fc5dd_row14_col5\" class=\"data row14 col5\" >1.5010</td>\n      <td id=\"T_fc5dd_row14_col6\" class=\"data row14 col6\" >5.4497</td>\n      <td id=\"T_fc5dd_row14_col7\" class=\"data row14 col7\" >0.3600</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row15\" class=\"row_heading level0 row15\" >lar</th>\n      <td id=\"T_fc5dd_row15_col0\" class=\"data row15 col0\" >Least Angle Regression</td>\n      <td id=\"T_fc5dd_row15_col1\" class=\"data row15 col1\" >26.3204</td>\n      <td id=\"T_fc5dd_row15_col2\" class=\"data row15 col2\" >1074.6430</td>\n      <td id=\"T_fc5dd_row15_col3\" class=\"data row15 col3\" >32.7024</td>\n      <td id=\"T_fc5dd_row15_col4\" class=\"data row15 col4\" >-0.5489</td>\n      <td id=\"T_fc5dd_row15_col5\" class=\"data row15 col5\" >1.5017</td>\n      <td id=\"T_fc5dd_row15_col6\" class=\"data row15 col6\" >5.7950</td>\n      <td id=\"T_fc5dd_row15_col7\" class=\"data row15 col7\" >0.6520</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row16\" class=\"row_heading level0 row16\" >lr</th>\n      <td id=\"T_fc5dd_row16_col0\" class=\"data row16 col0\" >Linear Regression</td>\n      <td id=\"T_fc5dd_row16_col1\" class=\"data row16 col1\" >26.8370</td>\n      <td id=\"T_fc5dd_row16_col2\" class=\"data row16 col2\" >1120.3078</td>\n      <td id=\"T_fc5dd_row16_col3\" class=\"data row16 col3\" >33.4555</td>\n      <td id=\"T_fc5dd_row16_col4\" class=\"data row16 col4\" >-0.6090</td>\n      <td id=\"T_fc5dd_row16_col5\" class=\"data row16 col5\" >1.4788</td>\n      <td id=\"T_fc5dd_row16_col6\" class=\"data row16 col6\" >5.5461</td>\n      <td id=\"T_fc5dd_row16_col7\" class=\"data row16 col7\" >1.7080</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row17\" class=\"row_heading level0 row17\" >par</th>\n      <td id=\"T_fc5dd_row17_col0\" class=\"data row17 col0\" >Passive Aggressive Regressor</td>\n      <td id=\"T_fc5dd_row17_col1\" class=\"data row17 col1\" >26.8351</td>\n      <td id=\"T_fc5dd_row17_col2\" class=\"data row17 col2\" >1120.6516</td>\n      <td id=\"T_fc5dd_row17_col3\" class=\"data row17 col3\" >33.4614</td>\n      <td id=\"T_fc5dd_row17_col4\" class=\"data row17 col4\" >-0.6091</td>\n      <td id=\"T_fc5dd_row17_col5\" class=\"data row17 col5\" >1.4749</td>\n      <td id=\"T_fc5dd_row17_col6\" class=\"data row17 col6\" >5.6060</td>\n      <td id=\"T_fc5dd_row17_col7\" class=\"data row17 col7\" >0.5940</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row18\" class=\"row_heading level0 row18\" >et</th>\n      <td id=\"T_fc5dd_row18_col0\" class=\"data row18 col0\" >Extra Trees Regressor</td>\n      <td id=\"T_fc5dd_row18_col1\" class=\"data row18 col1\" >27.6817</td>\n      <td id=\"T_fc5dd_row18_col2\" class=\"data row18 col2\" >1245.2112</td>\n      <td id=\"T_fc5dd_row18_col3\" class=\"data row18 col3\" >35.2349</td>\n      <td id=\"T_fc5dd_row18_col4\" class=\"data row18 col4\" >-0.7851</td>\n      <td id=\"T_fc5dd_row18_col5\" class=\"data row18 col5\" >1.7605</td>\n      <td id=\"T_fc5dd_row18_col6\" class=\"data row18 col6\" >5.3733</td>\n      <td id=\"T_fc5dd_row18_col7\" class=\"data row18 col7\" >10.4160</td>\n    </tr>\n    <tr>\n      <th id=\"T_fc5dd_level0_row19\" class=\"row_heading level0 row19\" >dt</th>\n      <td id=\"T_fc5dd_row19_col0\" class=\"data row19 col0\" >Decision Tree Regressor</td>\n      <td id=\"T_fc5dd_row19_col1\" class=\"data row19 col1\" >28.5123</td>\n      <td id=\"T_fc5dd_row19_col2\" class=\"data row19 col2\" >1321.7099</td>\n      <td id=\"T_fc5dd_row19_col3\" class=\"data row19 col3\" >36.2942</td>\n      <td id=\"T_fc5dd_row19_col4\" class=\"data row19 col4\" >-0.8977</td>\n      <td id=\"T_fc5dd_row19_col5\" class=\"data row19 col5\" >1.8726</td>\n      <td id=\"T_fc5dd_row19_col6\" class=\"data row19 col6\" >5.2563</td>\n      <td id=\"T_fc5dd_row19_col7\" class=\"data row19 col7\" >0.4120</td>\n    </tr>\n  </tbody>\n</table>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 최종 모델 학습\n",
        "final_model = finalize_model(best_model)\n",
        "\n",
        "# ✅ 테스트 데이터 예측\n",
        "predictions = predict_model(final_model, data=test_fp_df)\n",
        "\n",
        "# ✅ 예측값 0~100 범위로 클리핑\n",
        "final_predictions = np.clip(predictions['prediction_label'].values, 0, 100)\n",
        "\n",
        "# ✅ 제출 파일 생성\n",
        "submission_df['Inhibition'] = final_predictions\n",
        "submission_df.to_csv(\"/kaggle/working/submission_pycaret.csv\", index=False)\n",
        "\n",
        "print(\"✅ 제출 파일 생성 완료 → submission_pycaret.csv\")\n",
        "submission_df.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:13:01.869497Z",
          "iopub.execute_input": "2025-06-26T07:13:01.869782Z",
          "iopub.status.idle": "2025-06-26T07:13:05.527353Z",
          "shell.execute_reply.started": "2025-06-26T07:13:01.869761Z",
          "shell.execute_reply": "2025-06-26T07:13:05.526756Z"
        },
        "id": "jSaYg91zVAi3",
        "outputId": "430be468-48f5-486f-da7d-50284646a933"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "✅ 제출 파일 생성 완료 → submission_pycaret.csv\n",
          "output_type": "stream"
        },
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         ID  Inhibition\n0  TEST_000   34.716853\n1  TEST_001   29.709531\n2  TEST_002   25.155910\n3  TEST_003   38.779637\n4  TEST_004   26.630452",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Inhibition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_000</td>\n      <td>34.716853</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_001</td>\n      <td>29.709531</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_002</td>\n      <td>25.155910</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_003</td>\n      <td>38.779637</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_004</td>\n      <td>26.630452</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "from pycaret.regression import setup, compare_models, finalize_model, predict_model\n",
        "import warnings\n",
        "from rdkit import rdBase\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "rdBase.DisableLog('rdApp.error') # RDKit 에러 메시지 억제\n",
        "\n",
        "# ✅ 실제 Kaggle 경로 사용\n",
        "train_path = \"/kaggle/input/datafile1/train.csv\"\n",
        "test_path = \"/kaggle/input/datafile1/test.csv\"\n",
        "submission_path = \"/kaggle/input/datafile1/sample_submission.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "submission_df = pd.read_csv(submission_path)\n",
        "\n",
        "# --- 개선된 피처 추출 함수 (RDKit Descriptors + Morgan Fingerprints) ---\n",
        "def get_all_features(smiles_string, n_bits=2048, radius=2):\n",
        "    mol = Chem.MolFromSmiles(str(smiles_string))\n",
        "    if mol is None:\n",
        "        num_descriptors = len(Descriptors._descList)\n",
        "        return np.zeros(num_descriptors + n_bits, dtype=float)\n",
        "\n",
        "    descriptor_values = []\n",
        "    for desc_name, desc_func in Descriptors._descList:\n",
        "        try:\n",
        "            val = desc_func(mol)\n",
        "            if np.isnan(val) or np.isinf(val):\n",
        "                descriptor_values.append(0.0) # NaN 또는 Inf는 0으로 처리\n",
        "            else:\n",
        "                descriptor_values.append(val)\n",
        "        except:\n",
        "            descriptor_values.append(0.0) # 계산 오류 시 0으로 처리\n",
        "\n",
        "    try:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
        "        morgan_fp_values = np.array(fp, dtype=float)\n",
        "    except:\n",
        "        morgan_fp_values = np.zeros(n_bits, dtype=float) # 지문 계산 오류 시 0으로 처리\n",
        "\n",
        "    return np.concatenate([descriptor_values, morgan_fp_values])\n",
        "\n",
        "print(\"피처 추출 시작 (RDKit Descriptors + Morgan Fingerprints)...\")\n",
        "\n",
        "# 모든 SMILES에 대해 피처 추출\n",
        "train_features_raw = np.vstack(train_df['Canonical_Smiles'].apply(get_all_features).values)\n",
        "test_features_raw = np.vstack(test_df['Canonical_Smiles'].apply(get_all_features).values)\n",
        "\n",
        "# 컬럼 이름 생성 (Descriptors + Fingerprints)\n",
        "descriptor_names = [desc[0] for desc in Descriptors._descList]\n",
        "fp_columns = [f'FP_{i}' for i in range(2048)]\n",
        "all_feature_columns = descriptor_names + fp_columns\n",
        "\n",
        "train_features_df = pd.DataFrame(train_features_raw, columns=all_feature_columns)\n",
        "test_features_df = pd.DataFrame(test_features_raw, columns=all_feature_columns)\n",
        "\n",
        "print(f\"훈련 데이터 피처 형태: {train_features_df.shape}\")\n",
        "print(f\"테스트 데이터 피처 형태: {test_features_df.shape}\")\n",
        "\n",
        "# PyCaret용 최종 학습 데이터\n",
        "pycaret_train_df = pd.concat([train_features_df, train_df['Inhibition']], axis=1)\n",
        "\n",
        "# ✅ PyCaret 환경 설정 (normalize=True 유지, minmax 또는 zscore 고려)\n",
        "s = setup(data=pycaret_train_df,\n",
        "          target='Inhibition',\n",
        "          session_id=42,\n",
        "          fold=5,\n",
        "          normalize=True,\n",
        "          normalize_method='zscore', # 'minmax' 또는 'zscore' 시도\n",
        "          transformation=False, # 데이터 분포가 심하게 왜곡되지 않았다면 우선 False\n",
        "          n_jobs=-1, # CPU 코어 전체 사용\n",
        "          verbose=False)\n",
        "\n",
        "# ✅ 여러 모델 비교 및 최적 모델 선택\n",
        "# 앙상블 모델(LGBM, XGBoost, CatBoost)이 좋은 성능을 보일 수 있습니다.\n",
        "best_model = compare_models(sort='RMSE', n_select=1, include=['lightgbm', 'xgboost', 'catboost', 'et'])\n",
        "# 'et' (Extra Trees Regressor)는 무작위성을 높여 과적합을 줄이는 데 도움이 될 수 있습니다.\n",
        "\n",
        "# ✅ 최종 모델 학습\n",
        "final_model = finalize_model(best_model)\n",
        "\n",
        "# ✅ 테스트 데이터 예측\n",
        "predictions = predict_model(final_model, data=test_features_df)\n",
        "\n",
        "# ✅ 예측값 0~100 범위로 클리핑\n",
        "final_predictions = np.clip(predictions['prediction_label'].values, 0, 100)\n",
        "\n",
        "# ✅ 제출 파일 생성\n",
        "submission_df['Inhibition'] = final_predictions\n",
        "submission_df.to_csv(\"/kaggle/working/submission_pycaret_enhanced_features.csv\", index=False)\n",
        "\n",
        "print(\"✅ 제출 파일 생성 완료 → submission_pycaret_enhanced_features.csv\")\n",
        "submission_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:17:03.712821Z",
          "iopub.execute_input": "2025-06-26T07:17:03.713541Z",
          "iopub.status.idle": "2025-06-26T07:23:55.295651Z",
          "shell.execute_reply.started": "2025-06-26T07:17:03.713514Z",
          "shell.execute_reply": "2025-06-26T07:23:55.29503Z"
        },
        "id": "W0tBDXP1VAi3",
        "outputId": "9beee055-fe6a-4897-9b3a-e08bcc47b7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "피처 추출 시작 (RDKit Descriptors + Morgan Fingerprints)...\n훈련 데이터 피처 형태: (1681, 2256)\n테스트 데이터 피처 형태: (100, 2256)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<pandas.io.formats.style.Styler at 0x7a45c667d150>",
            "text/html": "<style type=\"text/css\">\n#T_306a9 th {\n  text-align: left;\n}\n#T_306a9_row0_col0, #T_306a9_row1_col0, #T_306a9_row1_col1, #T_306a9_row1_col2, #T_306a9_row1_col3, #T_306a9_row1_col4, #T_306a9_row1_col5, #T_306a9_row1_col6, #T_306a9_row2_col0, #T_306a9_row2_col1, #T_306a9_row2_col2, #T_306a9_row2_col3, #T_306a9_row2_col4, #T_306a9_row2_col5, #T_306a9_row2_col6, #T_306a9_row3_col0, #T_306a9_row3_col1, #T_306a9_row3_col2, #T_306a9_row3_col3, #T_306a9_row3_col4, #T_306a9_row3_col5, #T_306a9_row3_col6 {\n  text-align: left;\n}\n#T_306a9_row0_col1, #T_306a9_row0_col2, #T_306a9_row0_col3, #T_306a9_row0_col4, #T_306a9_row0_col5, #T_306a9_row0_col6 {\n  text-align: left;\n  background-color: yellow;\n}\n#T_306a9_row0_col7, #T_306a9_row1_col7, #T_306a9_row2_col7 {\n  text-align: left;\n  background-color: lightgrey;\n}\n#T_306a9_row3_col7 {\n  text-align: left;\n  background-color: yellow;\n  background-color: lightgrey;\n}\n</style>\n<table id=\"T_306a9\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_306a9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n      <th id=\"T_306a9_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n      <th id=\"T_306a9_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n      <th id=\"T_306a9_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n      <th id=\"T_306a9_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n      <th id=\"T_306a9_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n      <th id=\"T_306a9_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n      <th id=\"T_306a9_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_306a9_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n      <td id=\"T_306a9_row0_col0\" class=\"data row0 col0\" >Extra Trees Regressor</td>\n      <td id=\"T_306a9_row0_col1\" class=\"data row0 col1\" >19.8575</td>\n      <td id=\"T_306a9_row0_col2\" class=\"data row0 col2\" >588.3468</td>\n      <td id=\"T_306a9_row0_col3\" class=\"data row0 col3\" >24.2363</td>\n      <td id=\"T_306a9_row0_col4\" class=\"data row0 col4\" >0.1598</td>\n      <td id=\"T_306a9_row0_col5\" class=\"data row0 col5\" >1.3044</td>\n      <td id=\"T_306a9_row0_col6\" class=\"data row0 col6\" >5.0451</td>\n      <td id=\"T_306a9_row0_col7\" class=\"data row0 col7\" >8.3920</td>\n    </tr>\n    <tr>\n      <th id=\"T_306a9_level0_row1\" class=\"row_heading level0 row1\" >catboost</th>\n      <td id=\"T_306a9_row1_col0\" class=\"data row1 col0\" >CatBoost Regressor</td>\n      <td id=\"T_306a9_row1_col1\" class=\"data row1 col1\" >20.0771</td>\n      <td id=\"T_306a9_row1_col2\" class=\"data row1 col2\" >599.8983</td>\n      <td id=\"T_306a9_row1_col3\" class=\"data row1 col3\" >24.4617</td>\n      <td id=\"T_306a9_row1_col4\" class=\"data row1 col4\" >0.1440</td>\n      <td id=\"T_306a9_row1_col5\" class=\"data row1 col5\" >1.3232</td>\n      <td id=\"T_306a9_row1_col6\" class=\"data row1 col6\" >5.2188</td>\n      <td id=\"T_306a9_row1_col7\" class=\"data row1 col7\" >18.1340</td>\n    </tr>\n    <tr>\n      <th id=\"T_306a9_level0_row2\" class=\"row_heading level0 row2\" >lightgbm</th>\n      <td id=\"T_306a9_row2_col0\" class=\"data row2 col0\" >Light Gradient Boosting Machine</td>\n      <td id=\"T_306a9_row2_col1\" class=\"data row2 col1\" >20.1833</td>\n      <td id=\"T_306a9_row2_col2\" class=\"data row2 col2\" >611.8897</td>\n      <td id=\"T_306a9_row2_col3\" class=\"data row2 col3\" >24.7214</td>\n      <td id=\"T_306a9_row2_col4\" class=\"data row2 col4\" >0.1226</td>\n      <td id=\"T_306a9_row2_col5\" class=\"data row2 col5\" >1.3260</td>\n      <td id=\"T_306a9_row2_col6\" class=\"data row2 col6\" >5.0622</td>\n      <td id=\"T_306a9_row2_col7\" class=\"data row2 col7\" >41.4960</td>\n    </tr>\n    <tr>\n      <th id=\"T_306a9_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n      <td id=\"T_306a9_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n      <td id=\"T_306a9_row3_col1\" class=\"data row3 col1\" >20.7522</td>\n      <td id=\"T_306a9_row3_col2\" class=\"data row3 col2\" >653.9837</td>\n      <td id=\"T_306a9_row3_col3\" class=\"data row3 col3\" >25.5530</td>\n      <td id=\"T_306a9_row3_col4\" class=\"data row3 col4\" >0.0653</td>\n      <td id=\"T_306a9_row3_col5\" class=\"data row3 col5\" >1.3238</td>\n      <td id=\"T_306a9_row3_col6\" class=\"data row3 col6\" >5.1405</td>\n      <td id=\"T_306a9_row3_col7\" class=\"data row3 col7\" >1.6380</td>\n    </tr>\n  </tbody>\n</table>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "✅ 제출 파일 생성 완료 → submission_pycaret_enhanced_features.csv\n",
          "output_type": "stream"
        },
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         ID  Inhibition\n0  TEST_000   30.802648\n1  TEST_001   44.384227\n2  TEST_002   35.665714\n3  TEST_003   31.659298\n4  TEST_004   30.949165",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Inhibition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_000</td>\n      <td>30.802648</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_001</td>\n      <td>44.384227</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_002</td>\n      <td>35.665714</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_003</td>\n      <td>31.659298</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_004</td>\n      <td>30.949165</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 1. 필수 라이브러리\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ✅ 2. 경로 설정\n",
        "train_path = \"/kaggle/input/datafile1/train.csv\"\n",
        "test_path = \"/kaggle/input/datafile1/test.csv\"\n",
        "submission_path = \"/kaggle/input/datafile1/sample_submission.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "submission_df = pd.read_csv(submission_path)\n",
        "\n",
        "# ✅ 3. 피처 추출 함수 (Descriptors + Morgan Fingerprint)\n",
        "def get_all_features(smiles_string, n_bits=2048, radius=2):\n",
        "    mol = Chem.MolFromSmiles(str(smiles_string))\n",
        "    if mol is None:\n",
        "        num_descriptors = len(Descriptors._descList)\n",
        "        return np.zeros(num_descriptors + n_bits, dtype=float)\n",
        "\n",
        "    descriptor_values = []\n",
        "    for desc_name, desc_func in Descriptors._descList:\n",
        "        try:\n",
        "            val = desc_func(mol)\n",
        "            if np.isnan(val) or np.isinf(val):\n",
        "                descriptor_values.append(0.0)\n",
        "            else:\n",
        "                descriptor_values.append(val)\n",
        "        except:\n",
        "            descriptor_values.append(0.0)\n",
        "\n",
        "    try:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
        "        morgan_fp_values = np.array(fp, dtype=float)\n",
        "    except:\n",
        "        morgan_fp_values = np.zeros(n_bits, dtype=float)\n",
        "\n",
        "    return np.concatenate([descriptor_values, morgan_fp_values])\n",
        "\n",
        "# ✅ 4. 피처 생성\n",
        "X_train = np.vstack(train_df['Canonical_Smiles'].apply(get_all_features).values)\n",
        "X_test = np.vstack(test_df['Canonical_Smiles'].apply(get_all_features).values)\n",
        "y_train = train_df['Inhibition'].values\n",
        "\n",
        "# ✅ 5. Optuna 튜닝 함수 정의\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_estimators': 10000,\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 128),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.4, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.4, 1.0),\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10),\n",
        "    }\n",
        "\n",
        "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    rmse_list = []\n",
        "\n",
        "    for train_idx, valid_idx in cv.split(X_train):\n",
        "        X_tr, X_val = X_train[train_idx], X_train[valid_idx]\n",
        "        y_tr, y_val = y_train[train_idx], y_train[valid_idx]\n",
        "\n",
        "        model = lgb.LGBMRegressor(**params)\n",
        "        model.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            callbacks=[early_stopping(50, verbose=False), log_evaluation(0)]\n",
        "        )\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse_list.append(rmse)\n",
        "\n",
        "    return np.mean(rmse_list)\n",
        "\n",
        "# ✅ 6. Optuna 최적화 실행\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "# ✅ 7. 최적 파라미터로 최종 학습\n",
        "best_params = study.best_params\n",
        "best_params.update({\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'verbosity': -1,\n",
        "    'n_estimators': 10000\n",
        "})\n",
        "\n",
        "final_model = lgb.LGBMRegressor(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ 8. 테스트 예측 및 제출\n",
        "preds_test = final_model.predict(X_test)\n",
        "submission_df['Inhibition'] = np.clip(preds_test, 0, 100)\n",
        "submission_df.to_csv(\"/kaggle/working/submission_lgb_optuna.csv\", index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T07:55:03.368214Z",
          "iopub.execute_input": "2025-06-26T07:55:03.368568Z",
          "iopub.status.idle": "2025-06-26T08:04:22.757552Z",
          "shell.execute_reply.started": "2025-06-26T07:55:03.368547Z",
          "shell.execute_reply": "2025-06-26T08:04:22.756906Z"
        },
        "id": "7KOhaiPGVAi5",
        "outputId": "8d02a0bb-9186-4842-cf4c-c636dd0ab7cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[I 2025-06-26 07:55:20,977] A new study created in memory with name: no-name-2616e9e7-d549-4c0d-a54c-4b6d66d06ac2\n[I 2025-06-26 07:55:54,469] Trial 0 finished with value: 23.805197264077584 and parameters: {'learning_rate': 0.0017647770692221692, 'num_leaves': 109, 'min_child_samples': 60, 'subsample': 0.5452035018812312, 'colsample_bytree': 0.9512616919999783, 'reg_alpha': 0.14891393497198868, 'reg_lambda': 4.182169387373284}. Best is trial 0 with value: 23.805197264077584.\n[I 2025-06-26 07:55:56,246] Trial 1 finished with value: 23.79269849687569 and parameters: {'learning_rate': 0.0340990742122918, 'num_leaves': 44, 'min_child_samples': 100, 'subsample': 0.8517836263550383, 'colsample_bytree': 0.4633938259225815, 'reg_alpha': 0.14866449431159676, 'reg_lambda': 0.11849839071894082}. Best is trial 1 with value: 23.79269849687569.\n[I 2025-06-26 07:56:41,093] Trial 2 finished with value: 23.73422536892273 and parameters: {'learning_rate': 0.001576555487023821, 'num_leaves': 99, 'min_child_samples': 37, 'subsample': 0.8977351126869122, 'colsample_bytree': 0.7933762446358643, 'reg_alpha': 2.1612583236224867, 'reg_lambda': 0.0010168660516889992}. Best is trial 2 with value: 23.73422536892273.\n[I 2025-06-26 07:56:50,079] Trial 3 finished with value: 23.600052174372017 and parameters: {'learning_rate': 0.007143497352847598, 'num_leaves': 32, 'min_child_samples': 40, 'subsample': 0.6944969047880365, 'colsample_bytree': 0.44189636646190056, 'reg_alpha': 0.049499281294243844, 'reg_lambda': 2.02506201187026}. Best is trial 3 with value: 23.600052174372017.\n[I 2025-06-26 07:57:09,539] Trial 4 finished with value: 23.806918877746547 and parameters: {'learning_rate': 0.002765200712168013, 'num_leaves': 85, 'min_child_samples': 61, 'subsample': 0.9515783074506854, 'colsample_bytree': 0.8778672357663271, 'reg_alpha': 0.8613544249736829, 'reg_lambda': 0.046396469584315564}. Best is trial 3 with value: 23.600052174372017.\n[I 2025-06-26 07:57:33,155] Trial 5 finished with value: 23.724476637854266 and parameters: {'learning_rate': 0.002058917996833867, 'num_leaves': 51, 'min_child_samples': 73, 'subsample': 0.6296691892605332, 'colsample_bytree': 0.7263106417555523, 'reg_alpha': 6.8272186752143895, 'reg_lambda': 0.3031636063200651}. Best is trial 3 with value: 23.600052174372017.\n[I 2025-06-26 07:58:03,792] Trial 6 finished with value: 23.762422563168876 and parameters: {'learning_rate': 0.00221322569393897, 'num_leaves': 90, 'min_child_samples': 43, 'subsample': 0.4262653552060405, 'colsample_bytree': 0.861132614191821, 'reg_alpha': 0.026784762932837627, 'reg_lambda': 2.248057446841219}. Best is trial 3 with value: 23.600052174372017.\n[I 2025-06-26 07:58:39,152] Trial 7 finished with value: 23.93111492323353 and parameters: {'learning_rate': 0.0010546404314263722, 'num_leaves': 58, 'min_child_samples': 93, 'subsample': 0.7689193328086354, 'colsample_bytree': 0.7991811995818607, 'reg_alpha': 0.18726425397908797, 'reg_lambda': 0.17443605762770886}. Best is trial 3 with value: 23.600052174372017.\n[I 2025-06-26 07:58:51,750] Trial 8 finished with value: 23.760402096707466 and parameters: {'learning_rate': 0.004203009906732791, 'num_leaves': 22, 'min_child_samples': 61, 'subsample': 0.5496279304199934, 'colsample_bytree': 0.7677816701003957, 'reg_alpha': 2.48442842228377, 'reg_lambda': 0.008791562224446665}. Best is trial 3 with value: 23.600052174372017.\n[I 2025-06-26 07:59:03,306] Trial 9 finished with value: 23.821009348158615 and parameters: {'learning_rate': 0.029634314780315966, 'num_leaves': 64, 'min_child_samples': 12, 'subsample': 0.48116548385659025, 'colsample_bytree': 0.7018735499133102, 'reg_alpha': 8.476090270545939, 'reg_lambda': 1.3545192730682096}. Best is trial 3 with value: 23.600052174372017.\n[I 2025-06-26 07:59:10,659] Trial 10 finished with value: 23.531903079314155 and parameters: {'learning_rate': 0.009733740708019844, 'num_leaves': 21, 'min_child_samples': 20, 'subsample': 0.6742726331286399, 'colsample_bytree': 0.4014886066625916, 'reg_alpha': 0.0021359226984401266, 'reg_lambda': 0.7387068565623773}. Best is trial 10 with value: 23.531903079314155.\n[I 2025-06-26 07:59:18,834] Trial 11 finished with value: 23.47746620272324 and parameters: {'learning_rate': 0.009755265016517531, 'num_leaves': 22, 'min_child_samples': 14, 'subsample': 0.7096084146068287, 'colsample_bytree': 0.4086486573139707, 'reg_alpha': 0.001229070880026894, 'reg_lambda': 0.7413604520248299}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 07:59:29,877] Trial 12 finished with value: 23.55117941464777 and parameters: {'learning_rate': 0.014143554866474523, 'num_leaves': 21, 'min_child_samples': 6, 'subsample': 0.7386075270822073, 'colsample_bytree': 0.558908325148665, 'reg_alpha': 0.001041610810173452, 'reg_lambda': 0.5753674036121756}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 07:59:39,153] Trial 13 finished with value: 23.699796683432144 and parameters: {'learning_rate': 0.013498808505889873, 'num_leaves': 38, 'min_child_samples': 21, 'subsample': 0.6438580391695438, 'colsample_bytree': 0.5793450249416713, 'reg_alpha': 0.0010911159839988103, 'reg_lambda': 0.03536741218741454}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 07:59:41,991] Trial 14 finished with value: 23.86733448610554 and parameters: {'learning_rate': 0.08274446457855406, 'num_leaves': 124, 'min_child_samples': 24, 'subsample': 0.811660193878967, 'colsample_bytree': 0.5593937800995347, 'reg_alpha': 0.005735382500301517, 'reg_lambda': 7.937575226119321}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 07:59:53,474] Trial 15 finished with value: 23.565731943438802 and parameters: {'learning_rate': 0.007069366894353479, 'num_leaves': 32, 'min_child_samples': 25, 'subsample': 0.6596145382006647, 'colsample_bytree': 0.418943325493284, 'reg_alpha': 0.0053543202344213245, 'reg_lambda': 0.9574810451581428}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 08:00:01,750] Trial 16 finished with value: 23.685551739945524 and parameters: {'learning_rate': 0.02580356868611832, 'num_leaves': 68, 'min_child_samples': 15, 'subsample': 0.5790469854679173, 'colsample_bytree': 0.5109462163470977, 'reg_alpha': 0.0051611228955712315, 'reg_lambda': 0.5071412490325087}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 08:00:17,127] Trial 17 finished with value: 23.636314918282686 and parameters: {'learning_rate': 0.004902704533157667, 'num_leaves': 49, 'min_child_samples': 31, 'subsample': 0.7399138000757803, 'colsample_bytree': 0.6224482068388101, 'reg_alpha': 0.01872495122999475, 'reg_lambda': 0.01597917516736446}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 08:00:21,290] Trial 18 finished with value: 23.631814912074873 and parameters: {'learning_rate': 0.017023883493504127, 'num_leaves': 21, 'min_child_samples': 49, 'subsample': 0.9985959394754131, 'colsample_bytree': 0.4049360017600771, 'reg_alpha': 0.002043536237234994, 'reg_lambda': 7.656774928107927}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 08:00:35,636] Trial 19 finished with value: 23.813975265318607 and parameters: {'learning_rate': 0.058346161055797804, 'num_leaves': 77, 'min_child_samples': 7, 'subsample': 0.8171726642443344, 'colsample_bytree': 0.49347697110698174, 'reg_alpha': 0.010054700236680605, 'reg_lambda': 0.39981900950069776}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 08:00:41,113] Trial 20 finished with value: 23.73014636084834 and parameters: {'learning_rate': 0.01053607865127012, 'num_leaves': 35, 'min_child_samples': 81, 'subsample': 0.6079868856999421, 'colsample_bytree': 0.6524256081550114, 'reg_alpha': 0.002774628930002346, 'reg_lambda': 0.001986984024325022}. Best is trial 11 with value: 23.47746620272324.\n[I 2025-06-26 08:00:49,908] Trial 21 finished with value: 23.472350039855606 and parameters: {'learning_rate': 0.01634464070011464, 'num_leaves': 20, 'min_child_samples': 7, 'subsample': 0.7307461056720811, 'colsample_bytree': 0.5291283574522713, 'reg_alpha': 0.0010099364025526038, 'reg_lambda': 0.6956984844629999}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:00:55,959] Trial 22 finished with value: 23.619370915409853 and parameters: {'learning_rate': 0.020374266429385734, 'num_leaves': 29, 'min_child_samples': 18, 'subsample': 0.7111085297421528, 'colsample_bytree': 0.5132447733024726, 'reg_alpha': 0.0024084455741327734, 'reg_lambda': 0.19287773447901002}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:01:06,028] Trial 23 finished with value: 23.563593619191654 and parameters: {'learning_rate': 0.007889431461120151, 'num_leaves': 41, 'min_child_samples': 31, 'subsample': 0.6830548837429649, 'colsample_bytree': 0.4043269257367106, 'reg_alpha': 0.0010063891085254403, 'reg_lambda': 0.7527693909140811}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:01:31,372] Trial 24 finished with value: 23.5115101697554 and parameters: {'learning_rate': 0.004415600812557826, 'num_leaves': 25, 'min_child_samples': 5, 'subsample': 0.7856867554226616, 'colsample_bytree': 0.46946115112207143, 'reg_alpha': 0.013257907923995739, 'reg_lambda': 3.0988542733703874}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:02:26,644] Trial 25 finished with value: 23.6253490924583 and parameters: {'learning_rate': 0.003812564205642132, 'num_leaves': 55, 'min_child_samples': 6, 'subsample': 0.7859626865588102, 'colsample_bytree': 0.4735245504208255, 'reg_alpha': 0.01152466790397637, 'reg_lambda': 3.8365917331400077}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:02:47,496] Trial 26 finished with value: 23.620425174311077 and parameters: {'learning_rate': 0.00517856704225806, 'num_leaves': 29, 'min_child_samples': 14, 'subsample': 0.8826440972149315, 'colsample_bytree': 0.6156918571569787, 'reg_alpha': 0.048555692086467026, 'reg_lambda': 2.8158614981989274}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:02:50,820] Trial 27 finished with value: 23.621434355522535 and parameters: {'learning_rate': 0.04644786307589203, 'num_leaves': 45, 'min_child_samples': 28, 'subsample': 0.7524019072677235, 'colsample_bytree': 0.5213275752000173, 'reg_alpha': 0.43805700609842785, 'reg_lambda': 1.3902178430006926}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:03:22,748] Trial 28 finished with value: 23.639345713212066 and parameters: {'learning_rate': 0.0031142795904190836, 'num_leaves': 28, 'min_child_samples': 5, 'subsample': 0.8233359834174112, 'colsample_bytree': 0.6480958918995481, 'reg_alpha': 0.003918462636036396, 'reg_lambda': 0.06169081850198724}. Best is trial 21 with value: 23.472350039855606.\n[I 2025-06-26 08:03:38,100] Trial 29 finished with value: 23.57647496224672 and parameters: {'learning_rate': 0.010555640491626472, 'num_leaves': 39, 'min_child_samples': 12, 'subsample': 0.8919737061349822, 'colsample_bytree': 0.44936893912993353, 'reg_alpha': 0.012944971686989118, 'reg_lambda': 4.002585674091431}. Best is trial 21 with value: 23.472350039855606.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 1. 라이브러리\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "# ✅ 2. 데이터 로딩\n",
        "train = pd.read_csv(\"/kaggle/input/datafile1/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/datafile1/test.csv\")\n",
        "submission = pd.read_csv(\"/kaggle/input/datafile1/sample_submission.csv\")\n",
        "\n",
        "# ✅ 3. Feature Engineering (중요한 분자 feature 추출)\n",
        "def featurize(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return [0]*6\n",
        "    return [\n",
        "        Descriptors.MolWt(mol),         # 분자량\n",
        "        Descriptors.MolLogP(mol),       # 지용성\n",
        "        Descriptors.NumHDonors(mol),    # 수소 결합 donor 수\n",
        "        Descriptors.NumHAcceptors(mol), # 수소 결합 acceptor 수\n",
        "        Descriptors.TPSA(mol),          # 극성 표면적\n",
        "        Descriptors.NumRotatableBonds(mol) # 회전 가능한 결합 수\n",
        "    ]\n",
        "\n",
        "feature_names = ['MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors', 'TPSA', 'RotatableBonds']\n",
        "\n",
        "train_feats = train['Canonical_Smiles'].apply(featurize)\n",
        "test_feats = test['Canonical_Smiles'].apply(featurize)\n",
        "\n",
        "X = pd.DataFrame(train_feats.tolist(), columns=feature_names)\n",
        "X_test = pd.DataFrame(test_feats.tolist(), columns=feature_names)\n",
        "y = np.log1p(train['Inhibition'])  # ✅ log1p 변환\n",
        "\n",
        "# ✅ 4. 모델 정의 (Stacking)\n",
        "base_models = [\n",
        "    ('xgb', XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)),\n",
        "    ('lgbm', LGBMRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)),\n",
        "    ('cat', CatBoostRegressor(verbose=0, n_estimators=100, learning_rate=0.1, depth=3, random_state=42))\n",
        "]\n",
        "\n",
        "meta_model = RidgeCV()\n",
        "\n",
        "model = StackingRegressor(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ 5. 학습\n",
        "model.fit(X, y)\n",
        "\n",
        "# ✅ 6. 예측 및 역변환\n",
        "preds = model.predict(X_test)\n",
        "submission['Inhibition'] = np.clip(np.expm1(preds), 0, 100)\n",
        "submission.to_csv(\"submission_stacking_log1p_feats.csv\", index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T08:12:39.107846Z",
          "iopub.execute_input": "2025-06-26T08:12:39.108546Z",
          "iopub.status.idle": "2025-06-26T08:12:45.441869Z",
          "shell.execute_reply.started": "2025-06-26T08:12:39.108521Z",
          "shell.execute_reply": "2025-06-26T08:12:45.440862Z"
        },
        "id": "oicTkHWnVAi5",
        "outputId": "328f6dfe-2409-4277-8915-3b58716767db"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 797\n[LightGBM] [Info] Number of data points in the train set: 1681, number of used features: 6\n[LightGBM] [Info] Start training from score 2.996934\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 797\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 6\n[LightGBM] [Info] Start training from score 3.022786\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 797\n[LightGBM] [Info] Number of data points in the train set: 1344, number of used features: 6\n[LightGBM] [Info] Start training from score 3.068565\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 797\n[LightGBM] [Info] Total Bins 795\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 6\n[LightGBM] [Info] Start training from score 2.965889\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 6\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Start training from score 2.892919\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nNo further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] [LightGBM] [Warning] No further splits with positive gain, best gain: -infNo further splits with positive gain, best gain: -inf[LightGBM] [Warning] \nNo further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nNo further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nNo further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nNo further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 797\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 1345, number of used features: 6\n[LightGBM] [Info] Start training from score 3.034563\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error # MAE도 함께 확인 권장\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, AllChem # AllChem 임포트\n",
        "import warnings\n",
        "from rdkit import rdBase\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "rdBase.DisableLog('rdApp.error') # RDKit 에러 메시지 억제\n",
        "\n",
        "# ✅ 2. 데이터 로딩\n",
        "train = pd.read_csv(\"/kaggle/input/datafile1/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/datafile1/test.csv\")\n",
        "submission = pd.read_csv(\"/kaggle/input/datafile1/sample_submission.csv\")\n",
        "\n",
        "# ✅ 3. Feature Engineering (RDKit Descriptors + Morgan Fingerprints로 변경)\n",
        "def featurize_all(smiles_string, n_bits=2048, radius=2):\n",
        "    mol = Chem.MolFromSmiles(str(smiles_string))\n",
        "    if mol is None:\n",
        "        # 분자 생성 실패 시 모든 피처를 0으로 채움\n",
        "        num_descriptors = len(Descriptors._descList)\n",
        "        return np.zeros(num_descriptors + n_bits, dtype=float)\n",
        "\n",
        "    descriptor_values = []\n",
        "    for desc_name, desc_func in Descriptors._descList:\n",
        "        try:\n",
        "            val = desc_func(mol)\n",
        "            if np.isnan(val) or np.isinf(val):\n",
        "                descriptor_values.append(0.0) # NaN 또는 Inf는 0으로 처리\n",
        "            else:\n",
        "                descriptor_values.append(val)\n",
        "        except:\n",
        "            descriptor_values.append(0.0) # 계산 오류 시 0으로 처리\n",
        "\n",
        "    try:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
        "        morgan_fp_values = np.array(fp, dtype=float)\n",
        "    except:\n",
        "        morgan_fp_values = np.zeros(n_bits, dtype=float) # 지문 계산 오류 시 0으로 처리\n",
        "\n",
        "    return np.concatenate([descriptor_values, morgan_fp_values])\n",
        "\n",
        "print(\"피처 추출 시작 (RDKit Descriptors + Morgan Fingerprints)...\")\n",
        "\n",
        "train_features_raw = train['Canonical_Smiles'].apply(featurize_all)\n",
        "test_features_raw = test['Canonical_Smiles'].apply(featurize_all)\n",
        "\n",
        "# DataFrame 변환\n",
        "# 컬럼 이름 생성\n",
        "descriptor_names = [desc[0] for desc in Descriptors._descList]\n",
        "fp_columns = [f'FP_{i}' for i in range(2048)]\n",
        "feature_names_all = descriptor_names + fp_columns\n",
        "\n",
        "X = pd.DataFrame(train_features_raw.tolist(), columns=feature_names_all)\n",
        "X_test = pd.DataFrame(test_features_raw.tolist(), columns=feature_names_all)\n",
        "y = train['Inhibition'] # ✅ log1p 변환은 Stacking 모델에 따라 선택적으로 적용\n",
        "\n",
        "print(f\"훈련 데이터 피처 형태: {X.shape}\")\n",
        "print(f\"테스트 데이터 피처 형태: {X_test.shape}\")\n",
        "\n",
        "\n",
        "# ✅ 4. 모델 정의 (Stacking) - StandardScaler 파이프라인에 추가\n",
        "# 피처 수가 많아지면 스케일링이 중요해집니다.\n",
        "base_models = [\n",
        "    ('xgb', XGBRegressor(n_estimators=300, max_depth=5, learning_rate=0.05, random_state=42, n_jobs=-1)),\n",
        "    ('lgbm', LGBMRegressor(n_estimators=300, max_depth=5, learning_rate=0.05, random_state=42, n_jobs=-1, verbose=-1)),\n",
        "    ('cat', CatBoostRegressor(verbose=0, n_estimators=300, learning_rate=0.05, depth=6, random_state=42))\n",
        "]\n",
        "\n",
        "meta_model = RidgeCV(cv=5) # RidgeCV도 내부적으로 CV를 수행합니다.\n",
        "\n",
        "# Pipeline을 사용하여 스케일러와 스태킹 모델을 연결\n",
        "# StackingRegressor는 내부적으로 자체 CV를 수행하므로, 파이프라인의 CV와 혼동하지 않도록 주의.\n",
        "# 여기서는 피처 스케일링을 파이프라인에 포함시키는 것이 목적.\n",
        "pipeline_model = Pipeline([\n",
        "    ('scaler', StandardScaler()), # 데이터 스케일링 추가\n",
        "    ('stacking', StackingRegressor(\n",
        "        estimators=base_models,\n",
        "        final_estimator=meta_model,\n",
        "        cv=KFold(n_splits=5, shuffle=True, random_state=42), # 명시적으로 KFold 사용 (GroupKFold 문제 우회)\n",
        "        n_jobs=-1,\n",
        "        passthrough=True # 기본 모델의 예측 외에 원본 피처도 meta_model에 전달\n",
        "    ))\n",
        "])\n",
        "\n",
        "# ✅ 5. 학습\n",
        "print(\"\\n모델 학습 시작...\")\n",
        "pipeline_model.fit(X, y) # y는 이미 스케일링되지 않은 원래 값을 사용\n",
        "\n",
        "# ✅ 6. 예측 및 역변환\n",
        "print(\"예측 수행 및 제출 파일 생성...\")\n",
        "preds = pipeline_model.predict(X_test)\n",
        "submission['Inhibition'] = np.clip(preds, 0, 100) # 예측값 클리핑 (log1p를 사용하지 않았으므로 expm1 불필요)\n",
        "submission.to_csv(\"submission_stacking_enhanced_feats.csv\", index=False)\n",
        "\n",
        "print(\"\\n제출 파일 생성 완료 → submission_stacking_enhanced_feats.csv\")\n",
        "print(submission.head())\n",
        "\n",
        "# (선택 사항) 훈련 데이터에 대한 성능 확인\n",
        "train_preds = pipeline_model.predict(X)\n",
        "train_mae = mean_absolute_error(y, np.clip(train_preds, 0, 100))\n",
        "train_rmse = np.sqrt(mean_squared_error(y, np.clip(train_preds, 0, 100)))\n",
        "print(f\"훈련 데이터 MAE: {train_mae:.4f}\")\n",
        "print(f\"훈련 데이터 RMSE: {train_rmse:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T08:15:12.36691Z",
          "iopub.execute_input": "2025-06-26T08:15:12.367601Z",
          "iopub.status.idle": "2025-06-26T08:16:28.943427Z",
          "shell.execute_reply.started": "2025-06-26T08:15:12.367569Z",
          "shell.execute_reply": "2025-06-26T08:16:28.942552Z"
        },
        "id": "RWOp0DKTVAi6",
        "outputId": "013b5b41-c5e1-43df-e863-7e4e30926887"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "피처 추출 시작 (RDKit Descriptors + Morgan Fingerprints)...\n훈련 데이터 피처 형태: (1681, 2256)\n테스트 데이터 피처 형태: (100, 2256)\n\n모델 학습 시작...\n예측 수행 및 제출 파일 생성...\n\n제출 파일 생성 완료 → submission_stacking_enhanced_feats.csv\n         ID  Inhibition\n0  TEST_000   86.061659\n1  TEST_001    0.000000\n2  TEST_002   32.937639\n3  TEST_003   45.666493\n4  TEST_004   47.809909\n훈련 데이터 MAE: 6.0259\n훈련 데이터 RMSE: 7.8194\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}